{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBm1b65mkUOh"
      },
      "source": [
        "##Setup thÆ° viá»‡n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvazamOLaW_p",
        "outputId": "736749cc-44a7-439b-9fdf-137df452332c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Uwq_9ok3GYn8",
        "outputId": "67de7fcb-cd7b-481a-c5f5-a368fe06e750"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Oct 18 17:13:20 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   63C    P8              10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "tpoFTu-YjX2r",
        "outputId": "6ebfa0ad-44fa-49f4-9491-2551d9b339a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.16-py3-none-any.whl.metadata (34 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (10.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.4.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.19.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.5)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.9-py3-none-any.whl.metadata (9.3 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.4.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Downloading ultralytics-8.3.16-py3-none-any.whl (876 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m876.2/876.2 kB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.9-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.3.16 ultralytics-thop-2.0.9\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "CgF4da6s1sLF",
        "outputId": "7b1e91da-44b3-4dc6-8dbe-957cef2debad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-10-18 17:13:26--  https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8m.pt\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/521807533/0a8d2888-29a8-4d22-a130-b86c8174b33b?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20241018%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20241018T171326Z&X-Amz-Expires=300&X-Amz-Signature=0e609c0a0f8c1fd7946b8a292c50b3bf3609cd81d8295e1ae1718afbe2aa7cce&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dyolov8m.pt&response-content-type=application%2Foctet-stream [following]\n",
            "--2024-10-18 17:13:26--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/521807533/0a8d2888-29a8-4d22-a130-b86c8174b33b?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20241018%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20241018T171326Z&X-Amz-Expires=300&X-Amz-Signature=0e609c0a0f8c1fd7946b8a292c50b3bf3609cd81d8295e1ae1718afbe2aa7cce&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dyolov8m.pt&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 52117635 (50M) [application/octet-stream]\n",
            "Saving to: â€˜yolov8m.ptâ€™\n",
            "\n",
            "yolov8m.pt          100%[===================>]  49.70M   130MB/s    in 0.4s    \n",
            "\n",
            "2024-10-18 17:13:27 (130 MB/s) - â€˜yolov8m.ptâ€™ saved [52117635/52117635]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Táº£i pretrain model Yolov8m - medium\n",
        "!wget https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8m.pt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2u6Lf5PJJD6"
      },
      "source": [
        "##Predict vá»›i pretrain weights Yolov8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3c6VdGEIJRIE",
        "outputId": "9362bb71-0b45-4349-803c-d8390f3e9ffe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/yolo\", line 5, in <module>\n",
            "    from ultralytics.cfg import entrypoint\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/__init__.py\", line 11, in <module>\n",
            "    from ultralytics.models import NAS, RTDETR, SAM, YOLO, FastSAM, YOLOWorld\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/models/__init__.py\", line 3, in <module>\n",
            "    from .fastsam import FastSAM\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/models/fastsam/__init__.py\", line 3, in <module>\n",
            "    from .model import FastSAM\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/models/fastsam/model.py\", line 5, in <module>\n",
            "    from ultralytics.engine.model import Model\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/engine/model.py\", line 8, in <module>\n",
            "    import torch\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/__init__.py\", line 1827, in <module>\n",
            "    import torch.nn.quantized\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/quantized/__init__.py\", line 1, in <module>\n",
            "    from . import dynamic  # noqa: F403\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/quantized/dynamic/__init__.py\", line 1, in <module>\n",
            "    from torch.ao.nn.quantized.dynamic import *  # noqa: F403\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/ao/nn/quantized/__init__.py\", line 1, in <module>\n",
            "    from . import functional\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/ao/nn/quantized/functional.py\", line 11, in <module>\n",
            "    from .modules.utils import _pair_from_first\n",
            "  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\n",
            "  File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 879, in exec_module\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 975, in get_code\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 1074, in get_data\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "#Predict vá»›i CLI\n",
        "!yolo task=detect mode=predict model=yolov8m.pt source=\"https://vietmartjp.com/wp-content/uploads/2020/09/kiotviet_6fd05c54c48087068666ef6d4924c681.jpg\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "collapsed": true,
        "id": "UdIcIPEHK23L",
        "outputId": "a28d42cd-a19a-4cd0-852f-e8cc0665cb11"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "ename": "NotImplementedError",
          "evalue": "'source=0' webcam not supported in Colab and Kaggle notebooks. Try running 'source=0' in a local environment.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-78c0ed153778>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0multralytics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mYOLO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mYOLO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"yolov8m.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"0\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#\"https://vietmartjp.com/wp-content/uploads/2020/09/kiotviet_6fd05c54c48087068666ef6d4924c681.jpg\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, source, stream, predictor, **kwargs)\u001b[0m\n\u001b[1;32m    552\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprompts\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"set_prompts\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# for SAM-type models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_prompts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_cli\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_cli\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m     def track(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/predictor.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, source, model, stream, *args, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# merge list of Result into one\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_cli\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mgenerator_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;31m# Issuing `None` to a generator fires it up\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/predictor.py\u001b[0m in \u001b[0;36mstream_inference\u001b[0;34m(self, source, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# for thread-safe inference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m             \u001b[0;31m# Setup source every time predict is called\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_source\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msource\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0;31m# Check if save_dir/ label file exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/predictor.py\u001b[0m in \u001b[0;36msetup_source\u001b[0;34m(self, source)\u001b[0m\n\u001b[1;32m    196\u001b[0m             \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         )\n\u001b[0;32m--> 198\u001b[0;31m         self.dataset = load_inference_source(\n\u001b[0m\u001b[1;32m    199\u001b[0m             \u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m             \u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/data/build.py\u001b[0m in \u001b[0;36mload_inference_source\u001b[0;34m(source, batch, vid_stride, buffer)\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLoadStreams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvid_stride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvid_stride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mscreenshot\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLoadScreenshots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/data/loaders.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sources, vid_stride, buffer)\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnumeric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0ms\u001b[0m  \u001b[0;31m# i.e. s = '0' local webcam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mIS_COLAB\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mIS_KAGGLE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m                 raise NotImplementedError(\n\u001b[0m\u001b[1;32m    119\u001b[0m                     \u001b[0;34m\"'source=0' webcam not supported in Colab and Kaggle notebooks. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m                     \u001b[0;34m\"Try running 'source=0' in a local environment.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotImplementedError\u001b[0m: 'source=0' webcam not supported in Colab and Kaggle notebooks. Try running 'source=0' in a local environment."
          ]
        }
      ],
      "source": [
        "#Predict vá»›i Python\n",
        "from ultralytics import YOLO\n",
        "model = YOLO(\"yolov8m.pt\")\n",
        "results = model.predict(source=\"0\") #\"https://vietmartjp.com/wp-content/uploads/2020/09/kiotviet_6fd05c54c48087068666ef6d4924c681.jpg\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpPTLIxWkh-s"
      },
      "source": [
        "##Train vá»›i data custom\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "sf8b7f_nsZd7",
        "outputId": "b37156f3-fb75-4256-bba0-090181ddbd42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory â€˜/content/drive/MyDrive/datasetsâ€™: File exists\n",
            "/content/drive/MyDrive/datasets\n",
            "Collecting roboflow\n",
            "  Downloading roboflow-1.1.48-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from roboflow) (2024.8.30)\n",
            "Collecting idna==3.7 (from roboflow)\n",
            "  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: cycler in /usr/local/lib/python3.10/dist-packages (from roboflow) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.4.7)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from roboflow) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.26.4)\n",
            "Requirement already satisfied: opencv-python-headless==4.10.0.84 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.10.0.84)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from roboflow) (10.4.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.8.2)\n",
            "Collecting python-dotenv (from roboflow)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.32.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.16.0)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.2.3)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.66.5)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (6.0.2)\n",
            "Collecting requests-toolbelt (from roboflow)\n",
            "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
            "Collecting filetype (from roboflow)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (1.3.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (4.54.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (3.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->roboflow) (3.4.0)\n",
            "Downloading roboflow-1.1.48-py3-none-any.whl (80 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m80.3/80.3 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-3.7-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: filetype, python-dotenv, idna, requests-toolbelt, roboflow\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.10\n",
            "    Uninstalling idna-3.10:\n",
            "      Successfully uninstalled idna-3.10\n",
            "Successfully installed filetype-1.2.0 idna-3.7 python-dotenv-1.0.1 requests-toolbelt-1.0.0 roboflow-1.1.48\n",
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading Dataset Version Zip in Mat_Than-15 to yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31430/31430 [00:02<00:00, 10980.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to Mat_Than-15 in yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1108/1108 [00:07<00:00, 138.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file âœ… \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ],
      "source": [
        "!mkdir /content/drive/MyDrive/datasets\n",
        "%cd /content/drive/MyDrive/datasets\n",
        "\n",
        "#install file .yaml\n",
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"IAWHdDBsMLZlKBMEQqQk\")\n",
        "project = rf.workspace(\"buingocduc-phrxz\").project(\"mat_than-uhnpq\")\n",
        "version = project.version(15)\n",
        "dataset = version.download(\"yolov8\")\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "9PtNdWMTNcil",
        "outputId": "13a5e1d0-0c63-41e4-fdba-adc9f9034b0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n",
            "Ultralytics 8.3.16 ğŸš€ Python-3.10.12 torch-2.4.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8m.pt, data=datasets/Mat_Than-15/data.yaml, epochs=100, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train2\n",
            "Overriding model.yaml nc=80 with nc=4\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
            "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
            "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
            "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
            "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
            "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
            "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
            "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
            "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
            "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
            " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
            " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
            " 22        [15, 18, 21]  1   1142812  ultralytics.nn.modules.head.Detect           [4, [192, 384, 576]]          \n",
            "Model summary: 319 layers, 23,223,436 parameters, 23,223,420 gradients, 67.8 GFLOPs\n",
            "\n",
            "Transferred 433/511 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train2', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose \"Don't visualize my results\"\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLO11n...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/datasets/Mat_Than-15/train/labels... 486 images, 6 backgrounds, 0 corrupt: 100% 486/486 [00:05<00:00, 91.45it/s] \n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/drive/MyDrive/datasets/Mat_Than-15/train/labels.cache\n",
            "WARNING âš ï¸ Box and segment counts should be equal, but got len(segments) = 195, len(boxes) = 1785. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
            "/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.18 (you have 1.4.15). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "  check_for_updates()\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/datasets/Mat_Than-15/valid/labels... 41 images, 0 backgrounds, 0 corrupt: 100% 41/41 [00:01<00:00, 39.50it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/drive/MyDrive/datasets/Mat_Than-15/valid/labels.cache\n",
            "Plotting labels to runs/detect/train2/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00125, momentum=0.9) with parameter groups 83 weight(decay=0.0), 90 weight(decay=0.0005), 89 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train2\u001b[0m\n",
            "Starting training for 100 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      1/100      7.14G      1.195      2.643      1.426         40        640: 100% 31/31 [00:19<00:00,  1.63it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:02<00:00,  1.02s/it]\n",
            "                   all         41        198     0.0149      0.709      0.398      0.224\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      2/100      7.07G      1.127       1.77      1.331         26        640: 100% 31/31 [00:17<00:00,  1.82it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:01<00:00,  1.88it/s]\n",
            "                   all         41        198      0.321      0.211      0.224      0.126\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      3/100      6.93G      1.192      1.707      1.381         38        640: 100% 31/31 [00:16<00:00,  1.92it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:01<00:00,  1.87it/s]\n",
            "                   all         41        198      0.523      0.268      0.287      0.159\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      4/100      7.11G      1.181       1.63      1.388         30        640: 100% 31/31 [00:16<00:00,  1.92it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:01<00:00,  1.93it/s]\n",
            "                   all         41        198      0.284      0.572      0.265      0.136\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      5/100      7.04G      1.158      1.483      1.347         41        640: 100% 31/31 [00:16<00:00,  1.94it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:01<00:00,  1.15it/s]\n",
            "                   all         41        198      0.362      0.513      0.278      0.155\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      6/100      6.93G       1.14      1.395      1.354         45        640: 100% 31/31 [00:16<00:00,  1.85it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:01<00:00,  1.47it/s]\n",
            "                   all         41        198       0.52       0.46      0.368      0.213\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      7/100      7.12G      1.132      1.297      1.344         39        640: 100% 31/31 [00:16<00:00,  1.83it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:01<00:00,  1.57it/s]\n",
            "                   all         41        198      0.605      0.482      0.488      0.276\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      8/100      7.17G      1.086      1.241       1.31         34        640: 100% 31/31 [00:17<00:00,  1.75it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:00<00:00,  2.81it/s]\n",
            "                   all         41        198       0.61      0.574      0.608      0.402\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      9/100      7.07G      1.037      1.166      1.279         23        640: 100% 31/31 [00:17<00:00,  1.78it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:00<00:00,  2.55it/s]\n",
            "                   all         41        198      0.676      0.732      0.706      0.485\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     10/100      7.14G      1.001      1.104      1.241         22        640: 100% 31/31 [00:17<00:00,  1.74it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:00<00:00,  3.00it/s]\n",
            "                   all         41        198      0.705      0.635      0.698      0.492\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     11/100      7.16G      0.981      1.017      1.237         30        640: 100% 31/31 [00:18<00:00,  1.71it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:00<00:00,  2.78it/s]\n",
            "                   all         41        198      0.787        0.7      0.747      0.515\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     12/100      7.17G      0.978      1.018      1.225         40        640: 100% 31/31 [00:18<00:00,  1.71it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:00<00:00,  2.82it/s]\n",
            "                   all         41        198      0.744      0.719      0.762      0.534\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     13/100      7.07G     0.9271      0.972      1.219         27        640: 100% 31/31 [00:17<00:00,  1.75it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:00<00:00,  2.82it/s]\n",
            "                   all         41        198      0.804      0.757      0.766      0.577\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     14/100      7.14G     0.9302     0.9542      1.207         29        640: 100% 31/31 [00:17<00:00,  1.74it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:00<00:00,  2.82it/s]\n",
            "                   all         41        198      0.797      0.775      0.788       0.56\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     15/100      7.08G     0.8879     0.8808      1.177         36        640: 100% 31/31 [00:17<00:00,  1.76it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:00<00:00,  3.08it/s]\n",
            "                   all         41        198      0.867      0.662      0.773      0.563\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     16/100      7.16G     0.9035     0.8725      1.179         37        640: 100% 31/31 [00:17<00:00,  1.78it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:00<00:00,  2.96it/s]\n",
            "                   all         41        198      0.832      0.693      0.778      0.557\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     17/100      7.06G     0.8852     0.8643      1.175         33        640: 100% 31/31 [00:17<00:00,  1.76it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:00<00:00,  2.95it/s]\n",
            "                   all         41        198      0.669      0.741      0.764      0.557\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     18/100      7.14G     0.8475     0.8086      1.152         42        640: 100% 31/31 [00:17<00:00,  1.79it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:00<00:00,  3.10it/s]\n",
            "                   all         41        198      0.802      0.765      0.765      0.576\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     19/100      7.14G     0.8558     0.7847      1.159         41        640: 100% 31/31 [00:17<00:00,  1.80it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:00<00:00,  2.95it/s]\n",
            "                   all         41        198      0.854      0.799      0.838      0.618\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     20/100      7.14G     0.8585     0.8033      1.166         30        640: 100% 31/31 [00:18<00:00,  1.71it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:00<00:00,  2.62it/s]\n",
            "                   all         41        198      0.778      0.828      0.777      0.589\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     21/100      7.05G     0.8222     0.7668      1.141         69        640: 100% 31/31 [00:16<00:00,  1.88it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:00<00:00,  2.61it/s]\n",
            "                   all         41        198      0.796      0.822      0.828      0.617\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     22/100      7.16G     0.8155     0.7562      1.149         34        640: 100% 31/31 [00:16<00:00,  1.85it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:01<00:00,  1.94it/s]\n",
            "                   all         41        198       0.83      0.784      0.832      0.629\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     23/100      7.15G     0.8343     0.7672      1.144         24        640: 100% 31/31 [00:17<00:00,  1.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:01<00:00,  1.93it/s]\n",
            "                   all         41        198      0.802      0.765      0.812       0.62\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     24/100      7.14G     0.8327     0.7734      1.151         35        640: 100% 31/31 [00:16<00:00,  1.89it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:01<00:00,  1.85it/s]\n",
            "                   all         41        198      0.795      0.763      0.811      0.619\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     25/100      7.08G     0.8024     0.7325      1.129         25        640: 100% 31/31 [00:16<00:00,  1.88it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:01<00:00,  1.71it/s]\n",
            "                   all         41        198      0.786      0.783      0.799      0.591\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     26/100      7.16G     0.8089     0.7231       1.13         23        640: 100% 31/31 [00:16<00:00,  1.84it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:00<00:00,  2.07it/s]\n",
            "                   all         41        198      0.754      0.812      0.792        0.6\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     27/100      7.09G     0.8282     0.7488      1.139         34        640: 100% 31/31 [00:17<00:00,  1.79it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:00<00:00,  2.28it/s]\n",
            "                   all         41        198      0.794      0.836        0.8      0.614\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     28/100      6.96G     0.8192     0.7295      1.141         34        640: 100% 31/31 [00:17<00:00,  1.78it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:00<00:00,  2.39it/s]\n",
            "                   all         41        198      0.798      0.795      0.795      0.589\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     29/100      7.29G     0.7791     0.6976      1.122         48        640: 100% 31/31 [00:17<00:00,  1.78it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:00<00:00,  2.37it/s]\n",
            "                   all         41        198      0.789      0.821      0.775      0.599\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     30/100      7.16G      0.731     0.6581      1.085         36        640: 100% 31/31 [00:17<00:00,  1.77it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:00<00:00,  2.59it/s]\n",
            "                   all         41        198      0.831      0.749      0.795      0.618\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     31/100      7.15G     0.7251     0.6315      1.086         31        640: 100% 31/31 [00:17<00:00,  1.73it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:00<00:00,  2.36it/s]\n",
            "                   all         41        198      0.858      0.792        0.8      0.612\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     32/100      7.12G     0.7203      0.609      1.084         29        640: 100% 31/31 [00:17<00:00,  1.80it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:00<00:00,  2.43it/s]\n",
            "                   all         41        198      0.829      0.811      0.781      0.587\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     33/100      7.08G     0.7232     0.6334      1.077         25        640: 100% 31/31 [00:18<00:00,  1.68it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:00<00:00,  2.86it/s]\n",
            "                   all         41        198      0.774      0.805      0.783      0.614\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     34/100      6.93G     0.7463     0.6521      1.106         63        640: 100% 31/31 [00:17<00:00,  1.77it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:00<00:00,  3.08it/s]\n",
            "                   all         41        198      0.793      0.825      0.798      0.609\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     35/100      7.14G     0.7131     0.6155      1.078         36        640: 100% 31/31 [00:17<00:00,  1.78it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:00<00:00,  2.91it/s]\n",
            "                   all         41        198      0.848      0.744      0.807      0.622\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     36/100      7.15G     0.7288     0.6285      1.082         62        640: 100% 31/31 [00:17<00:00,  1.80it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:00<00:00,  2.99it/s]\n",
            "                   all         41        198      0.782      0.794      0.792        0.6\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     37/100      7.09G     0.7243     0.5979      1.085         22        640: 100% 31/31 [00:17<00:00,  1.80it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:00<00:00,  2.91it/s]\n",
            "                   all         41        198      0.816      0.806      0.775      0.603\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     38/100      7.15G     0.7107     0.6281      1.088         35        640: 100% 31/31 [00:17<00:00,  1.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:00<00:00,  3.05it/s]\n",
            "                   all         41        198      0.837      0.804      0.826       0.64\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     39/100      7.11G     0.6691     0.5681      1.048         41        640: 100% 31/31 [00:18<00:00,  1.69it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:00<00:00,  2.94it/s]\n",
            "                   all         41        198      0.804      0.849      0.825       0.63\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     40/100      7.16G     0.6569     0.5618      1.052         19        640: 100% 31/31 [00:17<00:00,  1.77it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:00<00:00,  2.92it/s]\n",
            "                   all         41        198      0.774      0.833      0.814      0.637\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     41/100      7.01G     0.6691     0.5571       1.06         24        640: 100% 31/31 [00:17<00:00,  1.78it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:00<00:00,  3.04it/s]\n",
            "                   all         41        198      0.816       0.84      0.815      0.626\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     42/100      7.15G     0.6986     0.5837      1.071         29        640: 100% 31/31 [00:17<00:00,  1.74it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:00<00:00,  3.03it/s]\n",
            "                   all         41        198      0.846       0.79      0.791      0.607\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     43/100      7.15G     0.6561     0.5648      1.059         89        640: 100% 31/31 [00:18<00:00,  1.71it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:01<00:00,  1.76it/s]\n",
            "                   all         41        198      0.834      0.811      0.813      0.642\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     44/100      7.17G     0.6972     0.6078      1.087         31        640: 100% 31/31 [00:19<00:00,  1.61it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:00<00:00,  2.45it/s]\n",
            "                   all         41        198      0.843      0.821      0.801      0.624\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     45/100      7.07G     0.6508     0.5501      1.039         33        640: 100% 31/31 [00:16<00:00,  1.87it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:01<00:00,  1.68it/s]\n",
            "                   all         41        198      0.804      0.818      0.816      0.633\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     46/100      7.13G     0.6356     0.5304      1.041         24        640: 100% 31/31 [00:16<00:00,  1.86it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:00<00:00,  2.24it/s]\n",
            "                   all         41        198      0.817      0.813      0.826      0.647\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     47/100      7.13G     0.6098     0.5264      1.016         59        640: 100% 31/31 [00:17<00:00,  1.78it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:01<00:00,  1.88it/s]\n",
            "                   all         41        198      0.799       0.85      0.848      0.665\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     48/100      7.18G     0.6126      0.508      1.017         32        640: 100% 31/31 [00:16<00:00,  1.84it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:01<00:00,  1.60it/s]\n",
            "                   all         41        198      0.847      0.779      0.826       0.66\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     49/100      7.06G     0.6222     0.5206      1.023         35        640: 100% 31/31 [00:16<00:00,  1.85it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:01<00:00,  1.46it/s]\n",
            "                   all         41        198      0.796      0.845      0.824       0.64\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     50/100      7.14G     0.6085     0.5072      1.013         42        640: 100% 31/31 [00:16<00:00,  1.87it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:01<00:00,  1.87it/s]\n",
            "                   all         41        198      0.803      0.813      0.818      0.637\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     51/100      7.15G     0.6939     0.6323      1.119         99        640:  13% 4/31 [00:02<00:13,  2.00it/s]"
          ]
        }
      ],
      "source": [
        "# Train vá»›i CLI\n",
        "%cd /content/drive/MyDrive/\n",
        "!yolo task=detect mode=train model=yolov8m.pt data=datasets/Mat_Than-15/data.yaml epochs=100 imgsz=640"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 532
        },
        "collapsed": true,
        "id": "MrP1OJQSuVIB",
        "outputId": "1c9096b0-ff67-4c50-a848-4b82e1e12931"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics 8.3.5 ğŸš€ Python-3.10.12 torch-2.4.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=/content/yolov8m.pt, data=/content/datasets/Mat_Than-5/data.yaml, epochs=50, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train7, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train7\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "Dataset '/content/datasets/Mat_Than-5/data.yaml' error âŒ \nDataset '/content/datasets/Mat_Than-5/data.yaml' images not found âš ï¸, missing path '/content/datasets/Mat_Than-5/..Mat_Than-5/valid/images'\nNote dataset download directory is '/content/datasets/datasets'. You can update this in '/root/.config/Ultralytics/settings.json'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36mget_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    558\u001b[0m             }:\n\u001b[0;32m--> 559\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_det_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    560\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"yaml_file\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/data/utils.py\u001b[0m in \u001b[0;36mcheck_det_dataset\u001b[0;34m(dataset, autodownload)\u001b[0m\n\u001b[1;32m    327\u001b[0m                 \u001b[0mm\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34mf\"\\nNote dataset download directory is '{DATASETS_DIR}'. You can update this in '{SETTINGS_FILE}'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: \nDataset '/content/datasets/Mat_Than-5/data.yaml' images not found âš ï¸, missing path '/content/datasets/Mat_Than-5/..Mat_Than-5/valid/images'\nNote dataset download directory is '/content/datasets/datasets'. You can update this in '/root/.config/Ultralytics/settings.json'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-4069baad05a0>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mYOLO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{HOME}/yolov8m.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf'/content/datasets/Mat_Than-5/data.yaml'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[1;32m    794\u001b[0m             \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"resume\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 796\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_smart_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"trainer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_callbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    797\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"resume\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# manually set model only if not resuming\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mckpt\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myaml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, cfg, overrides, _callbacks)\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_model_file_from_stem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# add suffix, i.e. yolov8n -> yolov8n.pt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch_distributed_zero_first\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLOCAL_RANK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# avoid auto-downloading dataset multiple times\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtestset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36mget_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    561\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"yaml_file\"\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# for validating 'yolo train data=url.zip' usage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memojis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Dataset '{clean_url(self.args.data)}' error âŒ {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"val\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Dataset '/content/datasets/Mat_Than-5/data.yaml' error âŒ \nDataset '/content/datasets/Mat_Than-5/data.yaml' images not found âš ï¸, missing path '/content/datasets/Mat_Than-5/..Mat_Than-5/valid/images'\nNote dataset download directory is '/content/datasets/datasets'. You can update this in '/root/.config/Ultralytics/settings.json'"
          ]
        }
      ],
      "source": [
        "#Train vá»›i Python API\n",
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO(\"/content/drive/MyDrive/datasets/yolov8m.pt\")\n",
        "results = model.train(data='/content/drive/MyDrive/datasets/Mat_Than-13/data.yaml', epochs=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pgc-jjZYNrPI"
      },
      "source": [
        "##Detect vá»›i data custom Image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ycngugbYwNJA",
        "outputId": "6016bb05-f494-4bbe-a2e7-38d0492fb1f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics 8.3.14 ğŸš€ Python-3.10.12 torch-2.4.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 236 layers, 23,204,569 parameters, 0 gradients, 67.4 GFLOPs\n",
            "\n",
            "Found https://cdn.prod.website-files.com/5d79a472ef0e0f4d25a3bd5e/5df05919fc0b1a55ac0561bc_ff.jpg locally at 5df05919fc0b1a55ac0561bc_ff.jpg\n",
            "image 1/1 /content/5df05919fc0b1a55ac0561bc_ff.jpg: 448x640 4 TuongOts, 95.2ms\n",
            "Speed: 3.5ms preprocess, 95.2ms inference, 886.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict2\u001b[0m\n",
            "ğŸ’¡ Learn more at https://docs.ultralytics.com/modes/predict\n"
          ]
        }
      ],
      "source": [
        "#detect vá»›i model custom 1\n",
        "!yolo task=detect mode=predict model=\"/content/drive/MyDrive/runs/detect/train8/weights/last.pt\" source=\"https://cdn.prod.website-files.com/5d79a472ef0e0f4d25a3bd5e/5df05919fc0b1a55ac0561bc_ff.jpg\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "nxUIafwoOCMK",
        "outputId": "e278021f-ce4f-4a63-ff5c-968bb71ed9a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics 8.3.5 ğŸš€ Python-3.10.12 torch-2.4.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 236 layers, 23,204,569 parameters, 0 gradients, 67.4 GFLOPs\n",
            "\n",
            "Downloading https://giavichinsu.com/wp-content/uploads/2023/11/tuong-ca-chinsu-500g-KV2.jpg to 'tuong-ca-chinsu-500g-KV2.jpg'...\n",
            "100% 113k/113k [00:00<00:00, 4.80MB/s]\n",
            "image 1/1 /content/drive/MyDrive/tuong-ca-chinsu-500g-KV2.jpg: 640x640 2 TuongCa_Chinsus, 34.4ms\n",
            "Speed: 3.1ms preprocess, 34.4ms inference, 566.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict3\u001b[0m\n",
            "ğŸ’¡ Learn more at https://docs.ultralytics.com/modes/predict\n"
          ]
        }
      ],
      "source": [
        "# Detect thá»­ vá»›i weights má»›i train 2\n",
        "!yolo task=detect mode=predict model=\"/content/drive/MyDrive/runs/detect/train5/weights/last.pt\" source=\"https://giavichinsu.com/wp-content/uploads/2023/11/tuong-ca-chinsu-500g-KV2.jpg\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-PZKeOUjF33a"
      },
      "source": [
        "## Detect vá»›i data custom trÃªn video."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pyDlR59ZJYzF"
      },
      "source": [
        "###Setup thÆ° viá»‡n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "MnwpU-ge_qnp",
        "outputId": "5cf6b727-30de-4a23-f981-622269ecb009"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: imutils in /usr/local/lib/python3.10/dist-packages (0.5.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (10.4.0)\n",
            "Collecting git+https://github.com/levan92/deep_sort_realtime.git\n",
            "  Cloning https://github.com/levan92/deep_sort_realtime.git to /tmp/pip-req-build-0bu6c01w\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/levan92/deep_sort_realtime.git /tmp/pip-req-build-0bu6c01w\n",
            "  Resolved https://github.com/levan92/deep_sort_realtime.git to commit 1fe0ae9052a6cb1edb3e88e573722598130dc635\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from deep-sort-realtime==1.3.2) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from deep-sort-realtime==1.3.2) (1.13.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from deep-sort-realtime==1.3.2) (4.10.0.84)\n",
            "Building wheels for collected packages: deep-sort-realtime\n",
            "  Building wheel for deep-sort-realtime (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for deep-sort-realtime: filename=deep_sort_realtime-1.3.2-py3-none-any.whl size=8429418 sha256=6d3067881acaaf3fc2baa38846456fe0bffffe93765fea5179773841ff646e65\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-vhqhou4j/wheels/63/aa/f8/a51265643f49aa02562694b0f2f27ad79e5807a64da70ee9ca\n",
            "Successfully built deep-sort-realtime\n",
            "Installing collected packages: deep-sort-realtime\n",
            "Successfully installed deep-sort-realtime-1.3.2\n"
          ]
        }
      ],
      "source": [
        "# CÃ i Ä‘áº·t torch (PyTorch)\n",
        "!pip install torch\n",
        "# CÃ i Ä‘áº·t imutils (dÃ¹ng Ä‘á»ƒ xá»­ lÃ½ áº£nh, video trong OpenCV)\n",
        "!pip install imutils\n",
        "# CÃ i Ä‘áº·t Pillow (thÆ° viá»‡n xá»­ lÃ½ áº£nh)\n",
        "!pip install Pillow\n",
        "# CÃ i Ä‘áº·t deep-sort-realtime\n",
        "!pip install git+https://github.com/levan92/deep_sort_realtime.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBSUSpKDLqEG"
      },
      "source": [
        "###Tracking with DeepSort and Counting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "collapsed": true,
        "id": "bhGfSGncGCCH",
        "colab": {
          "resources": {
            "http://localhost:8080/content/drive/MyDrive/output_video.mp4": {
              "data": "",
              "ok": false,
              "headers": [
                [
                  "content-length",
                  "0"
                ]
              ],
              "status": 404,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f9995033-f5e1-43ad-e49a-2b74c8e6f930"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 512x640 (no detections), 29.1ms\n",
            "Speed: 4.7ms preprocess, 29.1ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 27.3ms\n",
            "Speed: 5.0ms preprocess, 27.3ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 31.5ms\n",
            "Speed: 7.2ms preprocess, 31.5ms inference, 7.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 27.0ms\n",
            "Speed: 4.9ms preprocess, 27.0ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 29.5ms\n",
            "Speed: 8.7ms preprocess, 29.5ms inference, 2.7ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 38.4ms\n",
            "Speed: 4.7ms preprocess, 38.4ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 43.0ms\n",
            "Speed: 4.6ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 31.7ms\n",
            "Speed: 10.9ms preprocess, 31.7ms inference, 8.5ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 29.3ms\n",
            "Speed: 4.9ms preprocess, 29.3ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 35.6ms\n",
            "Speed: 4.7ms preprocess, 35.6ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 29.2ms\n",
            "Speed: 6.4ms preprocess, 29.2ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 29.0ms\n",
            "Speed: 5.5ms preprocess, 29.0ms inference, 7.4ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 26.4ms\n",
            "Speed: 5.6ms preprocess, 26.4ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 34.0ms\n",
            "Speed: 6.0ms preprocess, 34.0ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 26.4ms\n",
            "Speed: 5.0ms preprocess, 26.4ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 26.5ms\n",
            "Speed: 4.7ms preprocess, 26.5ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 26.4ms\n",
            "Speed: 4.5ms preprocess, 26.4ms inference, 3.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 26.4ms\n",
            "Speed: 5.1ms preprocess, 26.4ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 26.5ms\n",
            "Speed: 4.2ms preprocess, 26.5ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 26.5ms\n",
            "Speed: 4.8ms preprocess, 26.5ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 26.4ms\n",
            "Speed: 4.6ms preprocess, 26.4ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 26.4ms\n",
            "Speed: 4.9ms preprocess, 26.4ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 26.4ms\n",
            "Speed: 5.0ms preprocess, 26.4ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 26.5ms\n",
            "Speed: 7.8ms preprocess, 26.5ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 26.5ms\n",
            "Speed: 4.8ms preprocess, 26.5ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 26.4ms\n",
            "Speed: 5.4ms preprocess, 26.4ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 26.4ms\n",
            "Speed: 4.6ms preprocess, 26.4ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 26.4ms\n",
            "Speed: 5.6ms preprocess, 26.4ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 26.4ms\n",
            "Speed: 5.2ms preprocess, 26.4ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 26.5ms\n",
            "Speed: 6.6ms preprocess, 26.5ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 26.4ms\n",
            "Speed: 4.9ms preprocess, 26.4ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 26.5ms\n",
            "Speed: 6.4ms preprocess, 26.5ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 26.5ms\n",
            "Speed: 4.9ms preprocess, 26.5ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 26.5ms\n",
            "Speed: 5.2ms preprocess, 26.5ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 26.4ms\n",
            "Speed: 5.0ms preprocess, 26.4ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 26.5ms\n",
            "Speed: 4.9ms preprocess, 26.5ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 26.5ms\n",
            "Speed: 4.6ms preprocess, 26.5ms inference, 2.5ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 26.5ms\n",
            "Speed: 4.9ms preprocess, 26.5ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 26.9ms\n",
            "Speed: 7.8ms preprocess, 26.9ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 26.5ms\n",
            "Speed: 7.9ms preprocess, 26.5ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 26.5ms\n",
            "Speed: 4.3ms preprocess, 26.5ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 26.4ms\n",
            "Speed: 7.3ms preprocess, 26.4ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 26.4ms\n",
            "Speed: 4.4ms preprocess, 26.4ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 26.4ms\n",
            "Speed: 4.4ms preprocess, 26.4ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 27.2ms\n",
            "Speed: 4.8ms preprocess, 27.2ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 26.4ms\n",
            "Speed: 5.2ms preprocess, 26.4ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 26.5ms\n",
            "Speed: 5.0ms preprocess, 26.5ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 26.4ms\n",
            "Speed: 5.5ms preprocess, 26.4ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 26.4ms\n",
            "Speed: 5.5ms preprocess, 26.4ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 26.5ms\n",
            "Speed: 4.9ms preprocess, 26.5ms inference, 2.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 26.5ms\n",
            "Speed: 4.7ms preprocess, 26.5ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 26.5ms\n",
            "Speed: 5.4ms preprocess, 26.5ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 26.4ms\n",
            "Speed: 5.4ms preprocess, 26.4ms inference, 2.4ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 26.6ms\n",
            "Speed: 5.0ms preprocess, 26.6ms inference, 2.4ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 26.4ms\n",
            "Speed: 5.5ms preprocess, 26.4ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 26.4ms\n",
            "Speed: 5.1ms preprocess, 26.4ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 26.5ms\n",
            "Speed: 4.8ms preprocess, 26.5ms inference, 2.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 26.4ms\n",
            "Speed: 6.1ms preprocess, 26.4ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 26.5ms\n",
            "Speed: 5.0ms preprocess, 26.5ms inference, 1.7ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 26.5ms\n",
            "Speed: 5.1ms preprocess, 26.5ms inference, 2.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 26.4ms\n",
            "Speed: 4.8ms preprocess, 26.4ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 36.8ms\n",
            "Speed: 9.4ms preprocess, 36.8ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 26.4ms\n",
            "Speed: 5.4ms preprocess, 26.4ms inference, 4.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 29.2ms\n",
            "Speed: 5.4ms preprocess, 29.2ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 26.4ms\n",
            "Speed: 5.4ms preprocess, 26.4ms inference, 4.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 26.5ms\n",
            "Speed: 6.3ms preprocess, 26.5ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 26.5ms\n",
            "Speed: 6.7ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 31.1ms\n",
            "Speed: 11.7ms preprocess, 31.1ms inference, 4.5ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 TuongOt, 27.1ms\n",
            "Speed: 5.9ms preprocess, 27.1ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 26.4ms\n",
            "Speed: 6.2ms preprocess, 26.4ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 26.5ms\n",
            "Speed: 8.6ms preprocess, 26.5ms inference, 2.7ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 26.4ms\n",
            "Speed: 7.3ms preprocess, 26.4ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 TuongOt, 28.2ms\n",
            "Speed: 7.3ms preprocess, 28.2ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 35.2ms\n",
            "Speed: 8.1ms preprocess, 35.2ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 26.4ms\n",
            "Speed: 7.4ms preprocess, 26.4ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 26.4ms\n",
            "Speed: 5.3ms preprocess, 26.4ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 26.4ms\n",
            "Speed: 4.3ms preprocess, 26.4ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 26.4ms\n",
            "Speed: 4.2ms preprocess, 26.4ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 26.4ms\n",
            "Speed: 4.3ms preprocess, 26.4ms inference, 2.4ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 26.5ms\n",
            "Speed: 4.8ms preprocess, 26.5ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 26.5ms\n",
            "Speed: 6.3ms preprocess, 26.5ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 38.6ms\n",
            "Speed: 11.5ms preprocess, 38.6ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 26.4ms\n",
            "Speed: 4.4ms preprocess, 26.4ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 29.5ms\n",
            "Speed: 4.7ms preprocess, 29.5ms inference, 8.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 37.8ms\n",
            "Speed: 13.3ms preprocess, 37.8ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 35.9ms\n",
            "Speed: 4.6ms preprocess, 35.9ms inference, 6.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 26.5ms\n",
            "Speed: 5.2ms preprocess, 26.5ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 32.9ms\n",
            "Speed: 4.3ms preprocess, 32.9ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 27.2ms\n",
            "Speed: 14.7ms preprocess, 27.2ms inference, 1.7ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 45.2ms\n",
            "Speed: 4.2ms preprocess, 45.2ms inference, 1.7ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 26.4ms\n",
            "Speed: 5.5ms preprocess, 26.4ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 26.4ms\n",
            "Speed: 4.6ms preprocess, 26.4ms inference, 1.6ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 29.5ms\n",
            "Speed: 4.5ms preprocess, 29.5ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 27.8ms\n",
            "Speed: 12.2ms preprocess, 27.8ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 37.4ms\n",
            "Speed: 8.2ms preprocess, 37.4ms inference, 3.7ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 26.4ms\n",
            "Speed: 5.7ms preprocess, 26.4ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 34.6ms\n",
            "Speed: 4.1ms preprocess, 34.6ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 26.4ms\n",
            "Speed: 5.3ms preprocess, 26.4ms inference, 2.5ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 26.5ms\n",
            "Speed: 6.7ms preprocess, 26.5ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 31.1ms\n",
            "Speed: 7.2ms preprocess, 31.1ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 TuongOt, 26.4ms\n",
            "Speed: 4.8ms preprocess, 26.4ms inference, 3.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 35.4ms\n",
            "Speed: 4.2ms preprocess, 35.4ms inference, 2.6ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 26.4ms\n",
            "Speed: 5.0ms preprocess, 26.4ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 30.1ms\n",
            "Speed: 4.4ms preprocess, 30.1ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 26.4ms\n",
            "Speed: 4.9ms preprocess, 26.4ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 26.5ms\n",
            "Speed: 5.2ms preprocess, 26.5ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 26.5ms\n",
            "Speed: 4.9ms preprocess, 26.5ms inference, 2.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 31.8ms\n",
            "Speed: 6.9ms preprocess, 31.8ms inference, 4.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 28.4ms\n",
            "Speed: 4.5ms preprocess, 28.4ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 26.4ms\n",
            "Speed: 4.8ms preprocess, 26.4ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 26.4ms\n",
            "Speed: 5.6ms preprocess, 26.4ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 26.4ms\n",
            "Speed: 6.7ms preprocess, 26.4ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 26.5ms\n",
            "Speed: 6.7ms preprocess, 26.5ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 28.0ms\n",
            "Speed: 6.1ms preprocess, 28.0ms inference, 3.7ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 26.5ms\n",
            "Speed: 5.6ms preprocess, 26.5ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 31.7ms\n",
            "Speed: 5.0ms preprocess, 31.7ms inference, 2.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 26.5ms\n",
            "Speed: 4.7ms preprocess, 26.5ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 26.4ms\n",
            "Speed: 5.1ms preprocess, 26.4ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 26.5ms\n",
            "Speed: 4.8ms preprocess, 26.5ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 26.5ms\n",
            "Speed: 4.7ms preprocess, 26.5ms inference, 11.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 26.5ms\n",
            "Speed: 4.7ms preprocess, 26.5ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 27.3ms\n",
            "Speed: 6.4ms preprocess, 27.3ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 26.4ms\n",
            "Speed: 4.8ms preprocess, 26.4ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 26.5ms\n",
            "Speed: 7.7ms preprocess, 26.5ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 28.8ms\n",
            "Speed: 15.7ms preprocess, 28.8ms inference, 3.7ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 26.4ms\n",
            "Speed: 8.1ms preprocess, 26.4ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 28.7ms\n",
            "Speed: 10.5ms preprocess, 28.7ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 30.8ms\n",
            "Speed: 5.1ms preprocess, 30.8ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 26.4ms\n",
            "Speed: 5.0ms preprocess, 26.4ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 26.4ms\n",
            "Speed: 4.8ms preprocess, 26.4ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 26.5ms\n",
            "Speed: 4.8ms preprocess, 26.5ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 27.4ms\n",
            "Speed: 9.8ms preprocess, 27.4ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 26.4ms\n",
            "Speed: 5.8ms preprocess, 26.4ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 26.4ms\n",
            "Speed: 4.8ms preprocess, 26.4ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 26.4ms\n",
            "Speed: 4.9ms preprocess, 26.4ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 26.4ms\n",
            "Speed: 5.2ms preprocess, 26.4ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 26.6ms\n",
            "Speed: 5.2ms preprocess, 26.6ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 26.4ms\n",
            "Speed: 5.4ms preprocess, 26.4ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 26.4ms\n",
            "Speed: 5.1ms preprocess, 26.4ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 26.4ms\n",
            "Speed: 4.6ms preprocess, 26.4ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 27.5ms\n",
            "Speed: 4.5ms preprocess, 27.5ms inference, 2.5ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 26.4ms\n",
            "Speed: 4.9ms preprocess, 26.4ms inference, 3.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 26.4ms\n",
            "Speed: 4.3ms preprocess, 26.4ms inference, 1.5ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 26.4ms\n",
            "Speed: 6.0ms preprocess, 26.4ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 26.4ms\n",
            "Speed: 5.4ms preprocess, 26.4ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 26.4ms\n",
            "Speed: 7.4ms preprocess, 26.4ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 26.4ms\n",
            "Speed: 6.2ms preprocess, 26.4ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 26.5ms\n",
            "Speed: 4.9ms preprocess, 26.5ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 26.4ms\n",
            "Speed: 5.0ms preprocess, 26.4ms inference, 2.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 26.4ms\n",
            "Speed: 4.6ms preprocess, 26.4ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 26.4ms\n",
            "Speed: 7.0ms preprocess, 26.4ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 26.4ms\n",
            "Speed: 6.0ms preprocess, 26.4ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 27.1ms\n",
            "Speed: 7.0ms preprocess, 27.1ms inference, 3.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 26.4ms\n",
            "Speed: 6.9ms preprocess, 26.4ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 40.4ms\n",
            "Speed: 4.8ms preprocess, 40.4ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 26.4ms\n",
            "Speed: 4.4ms preprocess, 26.4ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 34.8ms\n",
            "Speed: 9.3ms preprocess, 34.8ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 27.1ms\n",
            "Speed: 5.0ms preprocess, 27.1ms inference, 2.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 30.8ms\n",
            "Speed: 4.4ms preprocess, 30.8ms inference, 9.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 34.5ms\n",
            "Speed: 4.8ms preprocess, 34.5ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 40.4ms\n",
            "Speed: 11.1ms preprocess, 40.4ms inference, 1.7ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 TuongOt, 26.4ms\n",
            "Speed: 5.1ms preprocess, 26.4ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 TuongOt, 26.6ms\n",
            "Speed: 7.1ms preprocess, 26.6ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 TuongOt, 41.7ms\n",
            "Speed: 5.0ms preprocess, 41.7ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 TuongOt, 28.2ms\n",
            "Speed: 4.7ms preprocess, 28.2ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 TuongOt, 37.6ms\n",
            "Speed: 5.5ms preprocess, 37.6ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 TuongOt, 26.4ms\n",
            "Speed: 4.9ms preprocess, 26.4ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 TuongOt, 32.4ms\n",
            "Speed: 6.6ms preprocess, 32.4ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 TuongOt, 30.3ms\n",
            "Speed: 4.8ms preprocess, 30.3ms inference, 2.4ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 TuongOt, 45.1ms\n",
            "Speed: 5.5ms preprocess, 45.1ms inference, 3.4ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 TuongOt, 37.5ms\n",
            "Speed: 4.4ms preprocess, 37.5ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 TuongOt, 31.5ms\n",
            "Speed: 14.2ms preprocess, 31.5ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 TuongOt, 28.8ms\n",
            "Speed: 9.5ms preprocess, 28.8ms inference, 7.5ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 TuongOt, 26.4ms\n",
            "Speed: 5.7ms preprocess, 26.4ms inference, 4.7ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 TuongOt, 26.5ms\n",
            "Speed: 4.8ms preprocess, 26.5ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 TuongOt, 26.4ms\n",
            "Speed: 4.8ms preprocess, 26.4ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 TuongOt, 26.4ms\n",
            "Speed: 5.0ms preprocess, 26.4ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 TuongOt, 26.4ms\n",
            "Speed: 4.6ms preprocess, 26.4ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 TuongOt, 31.0ms\n",
            "Speed: 17.3ms preprocess, 31.0ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 TuongOt, 28.2ms\n",
            "Speed: 7.6ms preprocess, 28.2ms inference, 2.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 TuongOt, 26.4ms\n",
            "Speed: 4.9ms preprocess, 26.4ms inference, 4.5ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 TuongOt, 26.4ms\n",
            "Speed: 5.0ms preprocess, 26.4ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 TuongOt, 26.5ms\n",
            "Speed: 4.5ms preprocess, 26.5ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 TuongOt, 26.4ms\n",
            "Speed: 4.9ms preprocess, 26.4ms inference, 2.4ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 TuongOt, 26.5ms\n",
            "Speed: 4.6ms preprocess, 26.5ms inference, 2.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 TuongOt, 26.4ms\n",
            "Speed: 4.3ms preprocess, 26.4ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 TuongOt, 26.4ms\n",
            "Speed: 4.5ms preprocess, 26.4ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 TuongOt, 26.4ms\n",
            "Speed: 4.6ms preprocess, 26.4ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 TuongOt, 28.3ms\n",
            "Speed: 5.6ms preprocess, 28.3ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 TuongOt, 26.4ms\n",
            "Speed: 5.2ms preprocess, 26.4ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 TuongOt, 31.1ms\n",
            "Speed: 6.3ms preprocess, 31.1ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 TuongOt, 26.4ms\n",
            "Speed: 4.7ms preprocess, 26.4ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 TuongOt, 26.4ms\n",
            "Speed: 5.0ms preprocess, 26.4ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 TuongOt, 26.4ms\n",
            "Speed: 5.3ms preprocess, 26.4ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 TuongOt, 26.5ms\n",
            "Speed: 4.9ms preprocess, 26.5ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 TuongOt, 26.5ms\n",
            "Speed: 5.9ms preprocess, 26.5ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 TuongOt, 26.5ms\n",
            "Speed: 4.7ms preprocess, 26.5ms inference, 2.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 TuongOt, 26.5ms\n",
            "Speed: 5.8ms preprocess, 26.5ms inference, 2.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 TuongOt, 28.2ms\n",
            "Speed: 5.0ms preprocess, 28.2ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 TuongOt, 26.4ms\n",
            "Speed: 7.6ms preprocess, 26.4ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 TuongOt, 26.5ms\n",
            "Speed: 5.6ms preprocess, 26.5ms inference, 2.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 TuongOt, 26.5ms\n",
            "Speed: 5.9ms preprocess, 26.5ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 TuongOt, 28.5ms\n",
            "Speed: 4.8ms preprocess, 28.5ms inference, 2.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 TuongOt, 26.4ms\n",
            "Speed: 5.3ms preprocess, 26.4ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 TuongOt, 26.5ms\n",
            "Speed: 4.9ms preprocess, 26.5ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 TuongOt, 26.4ms\n",
            "Speed: 5.6ms preprocess, 26.4ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 TuongOt, 26.4ms\n",
            "Speed: 7.8ms preprocess, 26.4ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 TuongOt, 26.4ms\n",
            "Speed: 5.5ms preprocess, 26.4ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 TuongOt, 26.5ms\n",
            "Speed: 5.4ms preprocess, 26.5ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 TuongOt, 26.4ms\n",
            "Speed: 4.9ms preprocess, 26.4ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 TuongOt, 28.3ms\n",
            "Speed: 6.9ms preprocess, 28.3ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 TuongOt, 26.4ms\n",
            "Speed: 4.8ms preprocess, 26.4ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 TuongOt, 26.5ms\n",
            "Speed: 4.9ms preprocess, 26.5ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 TuongOt, 26.5ms\n",
            "Speed: 4.7ms preprocess, 26.5ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 TuongOt, 26.5ms\n",
            "Speed: 5.5ms preprocess, 26.5ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 TuongOt, 26.4ms\n",
            "Speed: 7.4ms preprocess, 26.4ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 TuongOt, 26.5ms\n",
            "Speed: 4.6ms preprocess, 26.5ms inference, 2.4ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 TuongOt, 26.4ms\n",
            "Speed: 5.0ms preprocess, 26.4ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 TuongOt, 26.5ms\n",
            "Speed: 5.1ms preprocess, 26.5ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 TuongOt, 26.4ms\n",
            "Speed: 6.0ms preprocess, 26.4ms inference, 4.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 TuongOt, 27.1ms\n",
            "Speed: 5.2ms preprocess, 27.1ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 TuongOt, 26.4ms\n",
            "Speed: 5.6ms preprocess, 26.4ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 TuongOt, 26.8ms\n",
            "Speed: 4.6ms preprocess, 26.8ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 TuongOt, 37.5ms\n",
            "Speed: 5.1ms preprocess, 37.5ms inference, 10.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 TuongOt, 37.5ms\n",
            "Speed: 6.3ms preprocess, 37.5ms inference, 1.7ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 TuongOt, 32.3ms\n",
            "Speed: 13.9ms preprocess, 32.3ms inference, 2.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 TuongOt, 30.0ms\n",
            "Speed: 7.7ms preprocess, 30.0ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 TuongOt, 39.5ms\n",
            "Speed: 5.0ms preprocess, 39.5ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 TuongOt, 26.5ms\n",
            "Speed: 5.6ms preprocess, 26.5ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 TuongOt, 31.3ms\n",
            "Speed: 11.3ms preprocess, 31.3ms inference, 2.4ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 TuongOt, 26.6ms\n",
            "Speed: 8.1ms preprocess, 26.6ms inference, 4.4ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 TuongOt, 29.0ms\n",
            "Speed: 4.8ms preprocess, 29.0ms inference, 4.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 1 TuongOt, 28.5ms\n",
            "Speed: 9.8ms preprocess, 28.5ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 1 TuongOt, 26.4ms\n",
            "Speed: 8.8ms preprocess, 26.4ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 TuongOt, 35.3ms\n",
            "Speed: 7.9ms preprocess, 35.3ms inference, 9.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 1 TuongOt, 36.0ms\n",
            "Speed: 8.4ms preprocess, 36.0ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 TuongOt, 42.7ms\n",
            "Speed: 8.6ms preprocess, 42.7ms inference, 3.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 TuongOt, 26.5ms\n",
            "Speed: 4.8ms preprocess, 26.5ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 4 TuongCas, 1 TuongOt, 26.4ms\n",
            "Speed: 11.2ms preprocess, 26.4ms inference, 2.5ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 4 TuongCas, 1 TuongOt, 26.4ms\n",
            "Speed: 5.0ms preprocess, 26.4ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 3 TuongCas, 1 TuongOt, 26.5ms\n",
            "Speed: 4.4ms preprocess, 26.5ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 1 TuongOt, 26.5ms\n",
            "Speed: 4.7ms preprocess, 26.5ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 3 TuongCas, 1 TuongOt, 33.4ms\n",
            "Speed: 6.1ms preprocess, 33.4ms inference, 2.7ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 3 TuongCas, 1 TuongOt, 27.8ms\n",
            "Speed: 8.2ms preprocess, 27.8ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 3 TuongCas, 26.5ms\n",
            "Speed: 4.7ms preprocess, 26.5ms inference, 2.5ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 1 TuongOt, 26.5ms\n",
            "Speed: 4.9ms preprocess, 26.5ms inference, 3.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 3 TuongCas, 1 TuongOt, 26.5ms\n",
            "Speed: 4.3ms preprocess, 26.5ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 1 TuongOt, 26.4ms\n",
            "Speed: 10.0ms preprocess, 26.4ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 3 TuongCas, 26.4ms\n",
            "Speed: 6.1ms preprocess, 26.4ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 3 TuongCas, 1 TuongOt, 26.4ms\n",
            "Speed: 5.2ms preprocess, 26.4ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 3 TuongCas, 1 TuongOt, 26.4ms\n",
            "Speed: 5.1ms preprocess, 26.4ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 3 TuongCas, 1 TuongOt, 26.5ms\n",
            "Speed: 10.7ms preprocess, 26.5ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 3 TuongCas, 1 TuongOt, 26.5ms\n",
            "Speed: 5.1ms preprocess, 26.5ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 3 TuongCas, 1 TuongOt, 26.5ms\n",
            "Speed: 6.0ms preprocess, 26.5ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 3 TuongCas, 1 TuongOt, 26.5ms\n",
            "Speed: 5.9ms preprocess, 26.5ms inference, 2.6ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 3 TuongCas, 1 TuongOt, 26.6ms\n",
            "Speed: 4.8ms preprocess, 26.6ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 3 TuongCas, 1 TuongOt, 26.4ms\n",
            "Speed: 5.9ms preprocess, 26.4ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 3 TuongCas, 1 TuongOt, 26.5ms\n",
            "Speed: 9.3ms preprocess, 26.5ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 3 TuongCas, 1 TuongOt, 26.5ms\n",
            "Speed: 4.7ms preprocess, 26.5ms inference, 2.4ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 4 TuongCas, 1 TuongOt, 26.4ms\n",
            "Speed: 4.9ms preprocess, 26.4ms inference, 2.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 4 TuongCas, 1 TuongOt, 26.4ms\n",
            "Speed: 5.1ms preprocess, 26.4ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 5 TuongCas, 1 TuongOt, 26.4ms\n",
            "Speed: 5.7ms preprocess, 26.4ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 3 TuongCas, 1 TuongOt, 26.4ms\n",
            "Speed: 4.8ms preprocess, 26.4ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 3 TuongCas, 1 TuongOt, 26.4ms\n",
            "Speed: 5.0ms preprocess, 26.4ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 3 TuongCas, 1 TuongOt, 26.4ms\n",
            "Speed: 5.2ms preprocess, 26.4ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 3 TuongCas, 1 TuongOt, 26.5ms\n",
            "Speed: 5.0ms preprocess, 26.5ms inference, 2.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 3 TuongCas, 1 TuongOt, 26.5ms\n",
            "Speed: 5.0ms preprocess, 26.5ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 3 TuongCas, 1 TuongOt, 26.4ms\n",
            "Speed: 5.4ms preprocess, 26.4ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 3 TuongCas, 1 TuongOt, 26.4ms\n",
            "Speed: 5.0ms preprocess, 26.4ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 3 TuongCas, 1 TuongOt, 26.5ms\n",
            "Speed: 5.7ms preprocess, 26.5ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 4 TuongCas, 1 TuongOt, 26.4ms\n",
            "Speed: 5.3ms preprocess, 26.4ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 4 TuongCas, 1 TuongOt, 26.4ms\n",
            "Speed: 5.4ms preprocess, 26.4ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 4 TuongCas, 1 TuongOt, 26.5ms\n",
            "Speed: 13.4ms preprocess, 26.5ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 5 TuongCas, 1 TuongOt, 26.5ms\n",
            "Speed: 5.5ms preprocess, 26.5ms inference, 2.4ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 5 TuongCas, 1 TuongOt, 26.4ms\n",
            "Speed: 4.9ms preprocess, 26.4ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 4 TuongCas, 1 TuongOt, 26.4ms\n",
            "Speed: 5.5ms preprocess, 26.4ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 3 TuongCas, 1 TuongOt, 26.4ms\n",
            "Speed: 5.6ms preprocess, 26.4ms inference, 7.6ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 3 TuongCas, 2 TuongOts, 26.4ms\n",
            "Speed: 7.9ms preprocess, 26.4ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 4 TuongCas, 2 TuongOts, 28.2ms\n",
            "Speed: 13.7ms preprocess, 28.2ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 4 TuongCas, 2 TuongOts, 35.5ms\n",
            "Speed: 6.5ms preprocess, 35.5ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 4 TuongCas, 1 TuongOt, 31.2ms\n",
            "Speed: 7.4ms preprocess, 31.2ms inference, 6.5ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 4 TuongCas, 2 TuongOts, 27.9ms\n",
            "Speed: 13.6ms preprocess, 27.9ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 4 TuongCas, 1 TuongOt, 29.4ms\n",
            "Speed: 6.8ms preprocess, 29.4ms inference, 3.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 4 TuongCas, 2 TuongOts, 29.7ms\n",
            "Speed: 5.1ms preprocess, 29.7ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 4 TuongCas, 2 TuongOts, 29.3ms\n",
            "Speed: 5.2ms preprocess, 29.3ms inference, 8.7ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 5 TuongCas, 1 TuongOt, 26.5ms\n",
            "Speed: 5.0ms preprocess, 26.5ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 5 TuongCas, 1 TuongOt, 26.4ms\n",
            "Speed: 7.9ms preprocess, 26.4ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 5 TuongCas, 1 TuongOt, 32.7ms\n",
            "Speed: 4.4ms preprocess, 32.7ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 5 TuongCas, 1 TuongOt, 29.4ms\n",
            "Speed: 6.7ms preprocess, 29.4ms inference, 2.4ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 5 TuongCas, 1 TuongOt, 33.5ms\n",
            "Speed: 6.6ms preprocess, 33.5ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 4 TuongCas, 1 TuongOt, 30.0ms\n",
            "Speed: 7.6ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 5 TuongCas, 1 TuongOt, 26.4ms\n",
            "Speed: 4.5ms preprocess, 26.4ms inference, 4.5ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 5 TuongCas, 1 TuongOt, 26.4ms\n",
            "Speed: 4.8ms preprocess, 26.4ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 5 TuongCas, 1 TuongOt, 26.4ms\n",
            "Speed: 4.9ms preprocess, 26.4ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 5 TuongCas, 1 TuongOt, 26.4ms\n",
            "Speed: 4.7ms preprocess, 26.4ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 5 TuongCas, 1 TuongOt, 26.4ms\n",
            "Speed: 5.1ms preprocess, 26.4ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 5 TuongCas, 1 TuongOt, 26.4ms\n",
            "Speed: 5.1ms preprocess, 26.4ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 6 TuongCas, 1 TuongOt, 26.4ms\n",
            "Speed: 5.6ms preprocess, 26.4ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 6 TuongCas, 1 TuongOt, 26.5ms\n",
            "Speed: 4.6ms preprocess, 26.5ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 6 TuongCas, 1 TuongOt, 26.4ms\n",
            "Speed: 4.4ms preprocess, 26.4ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 5 TuongCas, 1 TuongOt, 28.1ms\n",
            "Speed: 4.4ms preprocess, 28.1ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 5 TuongCas, 1 TuongOt, 26.4ms\n",
            "Speed: 5.0ms preprocess, 26.4ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 6 TuongCas, 1 TuongOt, 26.5ms\n",
            "Speed: 6.1ms preprocess, 26.5ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 5 TuongCas, 1 TuongOt, 26.4ms\n",
            "Speed: 7.6ms preprocess, 26.4ms inference, 2.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 5 TuongCas, 1 TuongOt, 27.0ms\n",
            "Speed: 5.0ms preprocess, 27.0ms inference, 2.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 5 TuongCas, 1 TuongOt, 28.1ms\n",
            "Speed: 5.9ms preprocess, 28.1ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 5 TuongCas, 1 TuongOt, 26.4ms\n",
            "Speed: 4.9ms preprocess, 26.4ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 6 TuongCas, 1 TuongOt, 26.5ms\n",
            "Speed: 6.3ms preprocess, 26.5ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 4 TuongCas, 1 TuongOt, 28.7ms\n",
            "Speed: 10.5ms preprocess, 28.7ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 4 TuongCas, 1 TuongOt, 26.4ms\n",
            "Speed: 4.6ms preprocess, 26.4ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 4 TuongCas, 2 TuongOts, 26.4ms\n",
            "Speed: 4.5ms preprocess, 26.4ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 7 TuongCas, 1 TuongOt, 26.4ms\n",
            "Speed: 5.3ms preprocess, 26.4ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 4 TuongCas, 1 TuongOt, 26.4ms\n",
            "Speed: 4.8ms preprocess, 26.4ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 4 TuongCas, 1 TuongOt, 26.5ms\n",
            "Speed: 6.9ms preprocess, 26.5ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 4 TuongCas, 1 TuongOt, 26.5ms\n",
            "Speed: 6.2ms preprocess, 26.5ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 5 TuongCas, 1 TuongOt, 26.4ms\n",
            "Speed: 5.1ms preprocess, 26.4ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 4 TuongCas, 1 TuongOt, 26.4ms\n",
            "Speed: 4.9ms preprocess, 26.4ms inference, 4.5ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 3 TuongCas, 1 TuongOt, 26.5ms\n",
            "Speed: 4.8ms preprocess, 26.5ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 4 TuongCas, 1 TuongOt, 26.4ms\n",
            "Speed: 4.7ms preprocess, 26.4ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 4 TuongCas, 2 TuongOts, 28.9ms\n",
            "Speed: 6.6ms preprocess, 28.9ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 4 TuongCas, 1 TuongOt, 26.4ms\n",
            "Speed: 8.0ms preprocess, 26.4ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 3 TuongCas, 1 TuongOt, 26.5ms\n",
            "Speed: 4.8ms preprocess, 26.5ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 4 TuongCas, 1 TuongOt, 26.5ms\n",
            "Speed: 5.3ms preprocess, 26.5ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 4 TuongCas, 1 TuongOt, 26.4ms\n",
            "Speed: 5.7ms preprocess, 26.4ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 4 TuongCas, 1 TuongOt, 26.5ms\n",
            "Speed: 5.9ms preprocess, 26.5ms inference, 2.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 4 TuongCas, 1 TuongOt, 26.4ms\n",
            "Speed: 11.9ms preprocess, 26.4ms inference, 6.6ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 4 TuongCas, 1 TuongOt, 26.4ms\n",
            "Speed: 7.1ms preprocess, 26.4ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 3 TuongCas, 1 TuongOt, 26.4ms\n",
            "Speed: 5.4ms preprocess, 26.4ms inference, 4.5ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 3 TuongCas, 1 TuongOt, 26.5ms\n",
            "Speed: 5.1ms preprocess, 26.5ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 1 TuongOt, 26.4ms\n",
            "Speed: 6.7ms preprocess, 26.4ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 1 TuongOt, 26.4ms\n",
            "Speed: 5.2ms preprocess, 26.4ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 TuongOt, 26.4ms\n",
            "Speed: 8.1ms preprocess, 26.4ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 2 TuongOts, 26.6ms\n",
            "Speed: 6.0ms preprocess, 26.6ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 TuongOt, 26.5ms\n",
            "Speed: 7.2ms preprocess, 26.5ms inference, 2.5ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 1 TuongOt, 29.3ms\n",
            "Speed: 4.9ms preprocess, 29.3ms inference, 6.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 1 TuongOt, 28.7ms\n",
            "Speed: 5.1ms preprocess, 28.7ms inference, 5.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 1 TuongOt, 40.2ms\n",
            "Speed: 6.8ms preprocess, 40.2ms inference, 10.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 1 TuongOt, 26.4ms\n",
            "Speed: 8.7ms preprocess, 26.4ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 1 TuongOt, 27.1ms\n",
            "Speed: 4.6ms preprocess, 27.1ms inference, 3.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 1 TuongOt, 26.4ms\n",
            "Speed: 4.7ms preprocess, 26.4ms inference, 8.5ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 1 TuongOt, 26.4ms\n",
            "Speed: 4.4ms preprocess, 26.4ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 1 TuongOt, 32.1ms\n",
            "Speed: 4.2ms preprocess, 32.1ms inference, 1.7ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 1 TuongOt, 35.0ms\n",
            "Speed: 4.6ms preprocess, 35.0ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 1 TuongOt, 31.4ms\n",
            "Speed: 4.9ms preprocess, 31.4ms inference, 8.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 1 TuongOt, 41.8ms\n",
            "Speed: 5.0ms preprocess, 41.8ms inference, 6.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 3 TuongCas, 1 TuongOt, 26.4ms\n",
            "Speed: 11.5ms preprocess, 26.4ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 1 TuongOt, 26.4ms\n",
            "Speed: 5.6ms preprocess, 26.4ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 1 TuongOt, 28.4ms\n",
            "Speed: 4.6ms preprocess, 28.4ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 1 TuongOt, 27.2ms\n",
            "Speed: 6.7ms preprocess, 27.2ms inference, 3.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 3 TuongCas, 1 TuongOt, 34.8ms\n",
            "Speed: 7.8ms preprocess, 34.8ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 4 TuongCas, 1 TuongOt, 26.4ms\n",
            "Speed: 5.0ms preprocess, 26.4ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 3 TuongCas, 1 TuongOt, 26.4ms\n",
            "Speed: 4.7ms preprocess, 26.4ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 3 TuongCas, 1 TuongOt, 26.5ms\n",
            "Speed: 6.4ms preprocess, 26.5ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 3 TuongCas, 1 TuongOt, 26.4ms\n",
            "Speed: 5.0ms preprocess, 26.4ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 3 TuongCas, 1 TuongOt, 32.0ms\n",
            "Speed: 4.8ms preprocess, 32.0ms inference, 2.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 3 TuongCas, 1 TuongOt, 27.8ms\n",
            "Speed: 6.0ms preprocess, 27.8ms inference, 2.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 3 TuongCas, 1 TuongOt, 27.4ms\n",
            "Speed: 5.8ms preprocess, 27.4ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 3 TuongCas, 1 TuongOt, 26.5ms\n",
            "Speed: 5.0ms preprocess, 26.5ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 1 TuongOt, 26.4ms\n",
            "Speed: 5.8ms preprocess, 26.4ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 3 TuongCas, 1 TuongOt, 26.4ms\n",
            "Speed: 5.0ms preprocess, 26.4ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 3 TuongCas, 1 TuongOt, 26.5ms\n",
            "Speed: 5.4ms preprocess, 26.5ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 3 TuongCas, 1 TuongOt, 31.2ms\n",
            "Speed: 5.1ms preprocess, 31.2ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 3 TuongCas, 1 TuongOt, 26.4ms\n",
            "Speed: 4.7ms preprocess, 26.4ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 3 TuongCas, 1 TuongOt, 26.4ms\n",
            "Speed: 4.9ms preprocess, 26.4ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 3 TuongCas, 1 TuongOt, 26.4ms\n",
            "Speed: 8.3ms preprocess, 26.4ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 1 TuongOt, 28.1ms\n",
            "Speed: 4.8ms preprocess, 28.1ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 3 TuongCas, 1 TuongOt, 31.4ms\n",
            "Speed: 9.5ms preprocess, 31.4ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 3 TuongCas, 1 TuongOt, 26.4ms\n",
            "Speed: 4.7ms preprocess, 26.4ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 4 TuongCas, 1 TuongOt, 26.4ms\n",
            "Speed: 4.8ms preprocess, 26.4ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 3 TuongCas, 1 TuongOt, 26.7ms\n",
            "Speed: 4.6ms preprocess, 26.7ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 1 TuongOt, 26.4ms\n",
            "Speed: 4.7ms preprocess, 26.4ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 4 TuongCas, 1 TuongOt, 26.4ms\n",
            "Speed: 5.4ms preprocess, 26.4ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 5 TuongCas, 1 TuongOt, 26.4ms\n",
            "Speed: 5.1ms preprocess, 26.4ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 4 TuongCas, 1 TuongOt, 26.5ms\n",
            "Speed: 5.3ms preprocess, 26.5ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 4 TuongCas, 1 TuongOt, 26.4ms\n",
            "Speed: 4.6ms preprocess, 26.4ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 3 TuongCas, 1 TuongOt, 26.4ms\n",
            "Speed: 4.8ms preprocess, 26.4ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 3 TuongCas, 1 TuongOt, 26.5ms\n",
            "Speed: 6.4ms preprocess, 26.5ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 3 TuongCas, 1 TuongOt, 26.5ms\n",
            "Speed: 5.5ms preprocess, 26.5ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 3 TuongCas, 1 TuongOt, 26.2ms\n",
            "Speed: 5.4ms preprocess, 26.2ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 3 TuongCas, 1 TuongOt, 25.9ms\n",
            "Speed: 11.7ms preprocess, 25.9ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 3 TuongCas, 1 TuongOt, 25.8ms\n",
            "Speed: 6.1ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 2 TuongOts, 27.8ms\n",
            "Speed: 15.5ms preprocess, 27.8ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 2 TuongOts, 25.9ms\n",
            "Speed: 12.8ms preprocess, 25.9ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 2 TuongOts, 26.0ms\n",
            "Speed: 4.6ms preprocess, 26.0ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 2 TuongOts, 25.9ms\n",
            "Speed: 5.1ms preprocess, 25.9ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 3 TuongOts, 25.8ms\n",
            "Speed: 20.0ms preprocess, 25.8ms inference, 3.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 3 TuongOts, 25.9ms\n",
            "Speed: 4.9ms preprocess, 25.9ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 3 TuongCas, 3 TuongOts, 25.9ms\n",
            "Speed: 5.0ms preprocess, 25.9ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 4 TuongCas, 3 TuongOts, 25.9ms\n",
            "Speed: 5.2ms preprocess, 25.9ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 4 TuongCas, 3 TuongOts, 25.9ms\n",
            "Speed: 7.1ms preprocess, 25.9ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 3 TuongCas, 2 TuongOts, 35.0ms\n",
            "Speed: 11.8ms preprocess, 35.0ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 3 TuongOts, 33.7ms\n",
            "Speed: 6.8ms preprocess, 33.7ms inference, 7.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 3 TuongOts, 26.1ms\n",
            "Speed: 12.7ms preprocess, 26.1ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 2 TuongOts, 28.0ms\n",
            "Speed: 6.6ms preprocess, 28.0ms inference, 6.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 2 TuongOts, 32.9ms\n",
            "Speed: 10.5ms preprocess, 32.9ms inference, 3.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 2 TuongOts, 29.2ms\n",
            "Speed: 7.7ms preprocess, 29.2ms inference, 6.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 2 TuongOts, 40.1ms\n",
            "Speed: 5.4ms preprocess, 40.1ms inference, 4.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 3 TuongOts, 38.7ms\n",
            "Speed: 6.6ms preprocess, 38.7ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 3 TuongOts, 38.3ms\n",
            "Speed: 5.8ms preprocess, 38.3ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 1 TuongOt, 29.1ms\n",
            "Speed: 4.5ms preprocess, 29.1ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 3 TuongCas, 2 TuongOts, 35.5ms\n",
            "Speed: 4.6ms preprocess, 35.5ms inference, 8.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 2 TuongOts, 27.2ms\n",
            "Speed: 7.4ms preprocess, 27.2ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 1 TuongOt, 28.7ms\n",
            "Speed: 6.1ms preprocess, 28.7ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 1 TuongOt, 28.2ms\n",
            "Speed: 4.7ms preprocess, 28.2ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 2 TuongOts, 42.2ms\n",
            "Speed: 11.8ms preprocess, 42.2ms inference, 5.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 1 TuongOt, 36.5ms\n",
            "Speed: 4.6ms preprocess, 36.5ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 1 TuongOt, 26.3ms\n",
            "Speed: 11.9ms preprocess, 26.3ms inference, 2.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 1 TuongOt, 32.7ms\n",
            "Speed: 7.3ms preprocess, 32.7ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 1 TuongOt, 25.9ms\n",
            "Speed: 7.8ms preprocess, 25.9ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 1 TuongOt, 41.1ms\n",
            "Speed: 5.2ms preprocess, 41.1ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 1 TuongOt, 39.6ms\n",
            "Speed: 12.2ms preprocess, 39.6ms inference, 12.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 1 TuongOt, 27.8ms\n",
            "Speed: 4.8ms preprocess, 27.8ms inference, 2.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 1 TuongOt, 25.9ms\n",
            "Speed: 8.7ms preprocess, 25.9ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 1 TuongOt, 27.2ms\n",
            "Speed: 14.1ms preprocess, 27.2ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 1 TuongOt, 29.2ms\n",
            "Speed: 11.7ms preprocess, 29.2ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 37.2ms\n",
            "Speed: 5.3ms preprocess, 37.2ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 25.9ms\n",
            "Speed: 4.7ms preprocess, 25.9ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 25.9ms\n",
            "Speed: 4.8ms preprocess, 25.9ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 1 TuongOt, 25.9ms\n",
            "Speed: 4.5ms preprocess, 25.9ms inference, 2.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 25.9ms\n",
            "Speed: 5.6ms preprocess, 25.9ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 25.9ms\n",
            "Speed: 5.1ms preprocess, 25.9ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 25.9ms\n",
            "Speed: 4.6ms preprocess, 25.9ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 33.0ms\n",
            "Speed: 4.9ms preprocess, 33.0ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 25.9ms\n",
            "Speed: 4.5ms preprocess, 25.9ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 25.9ms\n",
            "Speed: 4.9ms preprocess, 25.9ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 25.8ms\n",
            "Speed: 4.2ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 25.9ms\n",
            "Speed: 4.5ms preprocess, 25.9ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 36.2ms\n",
            "Speed: 7.7ms preprocess, 36.2ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 25.9ms\n",
            "Speed: 4.9ms preprocess, 25.9ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 25.9ms\n",
            "Speed: 8.2ms preprocess, 25.9ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 25.9ms\n",
            "Speed: 4.7ms preprocess, 25.9ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 25.8ms\n",
            "Speed: 4.9ms preprocess, 25.8ms inference, 3.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 25.9ms\n",
            "Speed: 4.6ms preprocess, 25.9ms inference, 3.5ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 25.9ms\n",
            "Speed: 5.2ms preprocess, 25.9ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 25.9ms\n",
            "Speed: 5.2ms preprocess, 25.9ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 25.9ms\n",
            "Speed: 6.0ms preprocess, 25.9ms inference, 2.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 25.9ms\n",
            "Speed: 6.1ms preprocess, 25.9ms inference, 2.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 25.9ms\n",
            "Speed: 4.6ms preprocess, 25.9ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 25.9ms\n",
            "Speed: 5.1ms preprocess, 25.9ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 43.9ms\n",
            "Speed: 8.5ms preprocess, 43.9ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 25.9ms\n",
            "Speed: 5.3ms preprocess, 25.9ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 32.9ms\n",
            "Speed: 8.3ms preprocess, 32.9ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 25.9ms\n",
            "Speed: 5.1ms preprocess, 25.9ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 25.8ms\n",
            "Speed: 5.0ms preprocess, 25.8ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 25.9ms\n",
            "Speed: 4.8ms preprocess, 25.9ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 25.8ms\n",
            "Speed: 4.6ms preprocess, 25.8ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 26.2ms\n",
            "Speed: 4.2ms preprocess, 26.2ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 25.8ms\n",
            "Speed: 6.0ms preprocess, 25.8ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 25.9ms\n",
            "Speed: 4.9ms preprocess, 25.9ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 25.9ms\n",
            "Speed: 5.3ms preprocess, 25.9ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 25.9ms\n",
            "Speed: 12.9ms preprocess, 25.9ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 25.9ms\n",
            "Speed: 5.1ms preprocess, 25.9ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 25.9ms\n",
            "Speed: 4.8ms preprocess, 25.9ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 25.9ms\n",
            "Speed: 5.2ms preprocess, 25.9ms inference, 2.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 25.9ms\n",
            "Speed: 5.7ms preprocess, 25.9ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 25.9ms\n",
            "Speed: 5.6ms preprocess, 25.9ms inference, 2.7ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 31.2ms\n",
            "Speed: 4.3ms preprocess, 31.2ms inference, 4.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 25.8ms\n",
            "Speed: 4.9ms preprocess, 25.8ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 25.9ms\n",
            "Speed: 5.8ms preprocess, 25.9ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 25.8ms\n",
            "Speed: 4.6ms preprocess, 25.8ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 25.9ms\n",
            "Speed: 8.0ms preprocess, 25.9ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 25.9ms\n",
            "Speed: 7.4ms preprocess, 25.9ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 25.8ms\n",
            "Speed: 4.6ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 25.8ms\n",
            "Speed: 8.6ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 25.9ms\n",
            "Speed: 4.9ms preprocess, 25.9ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 25.9ms\n",
            "Speed: 4.9ms preprocess, 25.9ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 25.9ms\n",
            "Speed: 7.4ms preprocess, 25.9ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 3 TuongCas, 26.0ms\n",
            "Speed: 8.7ms preprocess, 26.0ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 25.8ms\n",
            "Speed: 6.7ms preprocess, 25.8ms inference, 9.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 25.9ms\n",
            "Speed: 8.5ms preprocess, 25.9ms inference, 8.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 40.3ms\n",
            "Speed: 4.7ms preprocess, 40.3ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 27.1ms\n",
            "Speed: 7.1ms preprocess, 27.1ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 30.2ms\n",
            "Speed: 11.7ms preprocess, 30.2ms inference, 1.7ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 31.8ms\n",
            "Speed: 20.7ms preprocess, 31.8ms inference, 4.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 28.9ms\n",
            "Speed: 5.9ms preprocess, 28.9ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 30.8ms\n",
            "Speed: 6.4ms preprocess, 30.8ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 26.8ms\n",
            "Speed: 4.8ms preprocess, 26.8ms inference, 2.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 30.3ms\n",
            "Speed: 4.4ms preprocess, 30.3ms inference, 5.5ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 26.5ms\n",
            "Speed: 5.9ms preprocess, 26.5ms inference, 3.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 31.4ms\n",
            "Speed: 4.4ms preprocess, 31.4ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 25.9ms\n",
            "Speed: 8.2ms preprocess, 25.9ms inference, 2.4ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 32.7ms\n",
            "Speed: 9.0ms preprocess, 32.7ms inference, 9.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 27.0ms\n",
            "Speed: 7.0ms preprocess, 27.0ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 34.0ms\n",
            "Speed: 8.5ms preprocess, 34.0ms inference, 4.4ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 35.7ms\n",
            "Speed: 10.6ms preprocess, 35.7ms inference, 8.7ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 3 TuongCas, 25.9ms\n",
            "Speed: 5.2ms preprocess, 25.9ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 25.9ms\n",
            "Speed: 4.8ms preprocess, 25.9ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 25.8ms\n",
            "Speed: 8.6ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 25.8ms\n",
            "Speed: 5.4ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 25.9ms\n",
            "Speed: 5.5ms preprocess, 25.9ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 25.9ms\n",
            "Speed: 6.7ms preprocess, 25.9ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 25.8ms\n",
            "Speed: 8.1ms preprocess, 25.8ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 25.9ms\n",
            "Speed: 6.9ms preprocess, 25.9ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 25.8ms\n",
            "Speed: 4.8ms preprocess, 25.8ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 28.9ms\n",
            "Speed: 8.1ms preprocess, 28.9ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 25.9ms\n",
            "Speed: 4.9ms preprocess, 25.9ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 25.9ms\n",
            "Speed: 4.7ms preprocess, 25.9ms inference, 2.5ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 25.9ms\n",
            "Speed: 5.2ms preprocess, 25.9ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 25.8ms\n",
            "Speed: 5.5ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 25.9ms\n",
            "Speed: 5.7ms preprocess, 25.9ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 25.9ms\n",
            "Speed: 4.8ms preprocess, 25.9ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 25.8ms\n",
            "Speed: 4.8ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 25.9ms\n",
            "Speed: 6.3ms preprocess, 25.9ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 25.9ms\n",
            "Speed: 6.7ms preprocess, 25.9ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 25.9ms\n",
            "Speed: 6.3ms preprocess, 25.9ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 25.8ms\n",
            "Speed: 4.8ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 25.9ms\n",
            "Speed: 4.3ms preprocess, 25.9ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 25.9ms\n",
            "Speed: 5.1ms preprocess, 25.9ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 25.9ms\n",
            "Speed: 5.2ms preprocess, 25.9ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 25.9ms\n",
            "Speed: 5.3ms preprocess, 25.9ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 26.3ms\n",
            "Speed: 8.7ms preprocess, 26.3ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 29.5ms\n",
            "Speed: 9.3ms preprocess, 29.5ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 25.9ms\n",
            "Speed: 10.3ms preprocess, 25.9ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 25.8ms\n",
            "Speed: 4.4ms preprocess, 25.8ms inference, 2.4ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 25.9ms\n",
            "Speed: 4.7ms preprocess, 25.9ms inference, 6.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 29.9ms\n",
            "Speed: 4.2ms preprocess, 29.9ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 25.8ms\n",
            "Speed: 4.4ms preprocess, 25.8ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 25.8ms\n",
            "Speed: 9.7ms preprocess, 25.8ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 27.2ms\n",
            "Speed: 4.8ms preprocess, 27.2ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 25.8ms\n",
            "Speed: 7.6ms preprocess, 25.8ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 29.9ms\n",
            "Speed: 9.3ms preprocess, 29.9ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 25.9ms\n",
            "Speed: 6.3ms preprocess, 25.9ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 25.9ms\n",
            "Speed: 5.0ms preprocess, 25.9ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 25.8ms\n",
            "Speed: 5.4ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 25.9ms\n",
            "Speed: 5.5ms preprocess, 25.9ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 25.8ms\n",
            "Speed: 5.3ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 29.9ms\n",
            "Speed: 5.1ms preprocess, 29.9ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 25.9ms\n",
            "Speed: 6.6ms preprocess, 25.9ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 25.9ms\n",
            "Speed: 6.3ms preprocess, 25.9ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 25.9ms\n",
            "Speed: 4.9ms preprocess, 25.9ms inference, 2.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 25.9ms\n",
            "Speed: 12.7ms preprocess, 25.9ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 25.8ms\n",
            "Speed: 5.8ms preprocess, 25.8ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 25.9ms\n",
            "Speed: 4.8ms preprocess, 25.9ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 25.9ms\n",
            "Speed: 5.3ms preprocess, 25.9ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 27.7ms\n",
            "Speed: 4.8ms preprocess, 27.7ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 30.5ms\n",
            "Speed: 5.1ms preprocess, 30.5ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 37.8ms\n",
            "Speed: 4.8ms preprocess, 37.8ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 33.1ms\n",
            "Speed: 4.9ms preprocess, 33.1ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 25.8ms\n",
            "Speed: 11.7ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 26.7ms\n",
            "Speed: 5.9ms preprocess, 26.7ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 30.2ms\n",
            "Speed: 11.7ms preprocess, 30.2ms inference, 1.7ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 34.0ms\n",
            "Speed: 10.2ms preprocess, 34.0ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 26.0ms\n",
            "Speed: 4.7ms preprocess, 26.0ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 26.5ms\n",
            "Speed: 4.8ms preprocess, 26.5ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 27.0ms\n",
            "Speed: 4.8ms preprocess, 27.0ms inference, 10.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 27.3ms\n",
            "Speed: 11.6ms preprocess, 27.3ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 32.4ms\n",
            "Speed: 10.0ms preprocess, 32.4ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 40.2ms\n",
            "Speed: 7.5ms preprocess, 40.2ms inference, 10.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 26.5ms\n",
            "Speed: 5.9ms preprocess, 26.5ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 31.1ms\n",
            "Speed: 4.8ms preprocess, 31.1ms inference, 9.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 37.3ms\n",
            "Speed: 7.0ms preprocess, 37.3ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 46.0ms\n",
            "Speed: 13.5ms preprocess, 46.0ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 25.9ms\n",
            "Speed: 5.5ms preprocess, 25.9ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 30.7ms\n",
            "Speed: 6.0ms preprocess, 30.7ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 25.9ms\n",
            "Speed: 5.7ms preprocess, 25.9ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 28.7ms\n",
            "Speed: 7.4ms preprocess, 28.7ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 26.1ms\n",
            "Speed: 5.0ms preprocess, 26.1ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 25.8ms\n",
            "Speed: 4.4ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 25.9ms\n",
            "Speed: 4.9ms preprocess, 25.9ms inference, 8.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 28.7ms\n",
            "Speed: 6.8ms preprocess, 28.7ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 26.3ms\n",
            "Speed: 5.9ms preprocess, 26.3ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 25.9ms\n",
            "Speed: 4.7ms preprocess, 25.9ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 27.5ms\n",
            "Speed: 5.1ms preprocess, 27.5ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 25.9ms\n",
            "Speed: 4.9ms preprocess, 25.9ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 25.9ms\n",
            "Speed: 4.6ms preprocess, 25.9ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 25.9ms\n",
            "Speed: 4.8ms preprocess, 25.9ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 25.9ms\n",
            "Speed: 6.6ms preprocess, 25.9ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 25.9ms\n",
            "Speed: 4.6ms preprocess, 25.9ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 25.9ms\n",
            "Speed: 5.8ms preprocess, 25.9ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 25.9ms\n",
            "Speed: 4.7ms preprocess, 25.9ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 25.9ms\n",
            "Speed: 4.8ms preprocess, 25.9ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 25.8ms\n",
            "Speed: 4.7ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 25.9ms\n",
            "Speed: 4.8ms preprocess, 25.9ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 28.3ms\n",
            "Speed: 6.1ms preprocess, 28.3ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 25.9ms\n",
            "Speed: 5.9ms preprocess, 25.9ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 30.7ms\n",
            "Speed: 14.4ms preprocess, 30.7ms inference, 3.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 27.5ms\n",
            "Speed: 5.0ms preprocess, 27.5ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 25.9ms\n",
            "Speed: 6.1ms preprocess, 25.9ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 26.3ms\n",
            "Speed: 5.7ms preprocess, 26.3ms inference, 2.4ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 25.9ms\n",
            "Speed: 6.1ms preprocess, 25.9ms inference, 2.4ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 25.8ms\n",
            "Speed: 8.9ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 25.9ms\n",
            "Speed: 8.5ms preprocess, 25.9ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 25.8ms\n",
            "Speed: 5.3ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 25.9ms\n",
            "Speed: 5.0ms preprocess, 25.9ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 25.9ms\n",
            "Speed: 4.6ms preprocess, 25.9ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 25.9ms\n",
            "Speed: 4.4ms preprocess, 25.9ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 25.9ms\n",
            "Speed: 8.3ms preprocess, 25.9ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 25.9ms\n",
            "Speed: 8.9ms preprocess, 25.9ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 25.8ms\n",
            "Speed: 7.5ms preprocess, 25.8ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 25.9ms\n",
            "Speed: 9.5ms preprocess, 25.9ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 haohao, 25.9ms\n",
            "Speed: 7.9ms preprocess, 25.9ms inference, 2.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 haohao, 25.9ms\n",
            "Speed: 5.7ms preprocess, 25.9ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 haohao, 25.8ms\n",
            "Speed: 5.2ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 haohao, 25.9ms\n",
            "Speed: 7.4ms preprocess, 25.9ms inference, 7.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 haohao, 25.9ms\n",
            "Speed: 6.4ms preprocess, 25.9ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 haohao, 26.0ms\n",
            "Speed: 5.3ms preprocess, 26.0ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 haohao, 25.9ms\n",
            "Speed: 5.5ms preprocess, 25.9ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 haohao, 25.9ms\n",
            "Speed: 5.7ms preprocess, 25.9ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 haohao, 26.0ms\n",
            "Speed: 7.0ms preprocess, 26.0ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 haohao, 25.9ms\n",
            "Speed: 6.2ms preprocess, 25.9ms inference, 2.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 haohao, 25.9ms\n",
            "Speed: 5.8ms preprocess, 25.9ms inference, 2.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 haohao, 25.9ms\n",
            "Speed: 6.1ms preprocess, 25.9ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 haohao, 25.9ms\n",
            "Speed: 5.5ms preprocess, 25.9ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 1 haohao, 25.9ms\n",
            "Speed: 7.5ms preprocess, 25.9ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 haohao, 25.8ms\n",
            "Speed: 4.5ms preprocess, 25.8ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 haohao, 26.7ms\n",
            "Speed: 6.0ms preprocess, 26.7ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 haohao, 25.9ms\n",
            "Speed: 4.3ms preprocess, 25.9ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 haohao, 25.9ms\n",
            "Speed: 4.6ms preprocess, 25.9ms inference, 5.5ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 haohao, 37.5ms\n",
            "Speed: 7.3ms preprocess, 37.5ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 haohao, 33.7ms\n",
            "Speed: 4.6ms preprocess, 33.7ms inference, 14.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 haohao, 25.9ms\n",
            "Speed: 10.3ms preprocess, 25.9ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 1 haohao, 27.6ms\n",
            "Speed: 9.6ms preprocess, 27.6ms inference, 7.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 1 haohao, 29.6ms\n",
            "Speed: 4.3ms preprocess, 29.6ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 haohao, 25.8ms\n",
            "Speed: 4.6ms preprocess, 25.8ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 haohao, 27.4ms\n",
            "Speed: 4.9ms preprocess, 27.4ms inference, 2.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 haohao, 25.8ms\n",
            "Speed: 8.0ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 1 haohao, 29.1ms\n",
            "Speed: 14.2ms preprocess, 29.1ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 haohao, 28.5ms\n",
            "Speed: 7.0ms preprocess, 28.5ms inference, 1.7ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 haohao, 44.4ms\n",
            "Speed: 6.7ms preprocess, 44.4ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 haohao, 33.3ms\n",
            "Speed: 11.9ms preprocess, 33.3ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 1 TuongOt, 1 haohao, 35.0ms\n",
            "Speed: 4.5ms preprocess, 35.0ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 TuongOt, 1 haohao, 28.2ms\n",
            "Speed: 5.8ms preprocess, 28.2ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 haohao, 26.6ms\n",
            "Speed: 8.8ms preprocess, 26.6ms inference, 4.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 haohao, 25.9ms\n",
            "Speed: 6.2ms preprocess, 25.9ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 haohao, 30.7ms\n",
            "Speed: 4.8ms preprocess, 30.7ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 haohao, 25.8ms\n",
            "Speed: 8.1ms preprocess, 25.8ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 haohao, 25.9ms\n",
            "Speed: 6.7ms preprocess, 25.9ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 haohao, 25.9ms\n",
            "Speed: 5.5ms preprocess, 25.9ms inference, 2.4ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 haohao, 25.9ms\n",
            "Speed: 7.2ms preprocess, 25.9ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 haohao, 26.4ms\n",
            "Speed: 8.2ms preprocess, 26.4ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 haohao, 25.9ms\n",
            "Speed: 4.6ms preprocess, 25.9ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 haohao, 25.9ms\n",
            "Speed: 4.8ms preprocess, 25.9ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 haohao, 26.9ms\n",
            "Speed: 5.7ms preprocess, 26.9ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 1 haohao, 28.1ms\n",
            "Speed: 5.9ms preprocess, 28.1ms inference, 3.6ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 1 haohao, 25.9ms\n",
            "Speed: 7.5ms preprocess, 25.9ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 1 TuongOt, 25.9ms\n",
            "Speed: 4.8ms preprocess, 25.9ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 1 haohao, 29.6ms\n",
            "Speed: 13.0ms preprocess, 29.6ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 haohao, 25.9ms\n",
            "Speed: 5.2ms preprocess, 25.9ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 haohao, 25.9ms\n",
            "Speed: 7.2ms preprocess, 25.9ms inference, 2.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 1 TuongOt, 1 haohao, 25.8ms\n",
            "Speed: 4.8ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 1 TuongOt, 1 haohao, 25.9ms\n",
            "Speed: 4.8ms preprocess, 25.9ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 1 haohao, 25.9ms\n",
            "Speed: 5.4ms preprocess, 25.9ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 haohao, 25.9ms\n",
            "Speed: 5.4ms preprocess, 25.9ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 haohao, 26.1ms\n",
            "Speed: 4.9ms preprocess, 26.1ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 haohao, 25.9ms\n",
            "Speed: 4.6ms preprocess, 25.9ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 haohao, 25.8ms\n",
            "Speed: 4.4ms preprocess, 25.8ms inference, 2.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 haohao, 25.9ms\n",
            "Speed: 4.6ms preprocess, 25.9ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 haohao, 25.9ms\n",
            "Speed: 5.3ms preprocess, 25.9ms inference, 2.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 haohao, 25.9ms\n",
            "Speed: 5.5ms preprocess, 25.9ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 haohao, 25.9ms\n",
            "Speed: 8.3ms preprocess, 25.9ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 haohao, 25.9ms\n",
            "Speed: 5.3ms preprocess, 25.9ms inference, 2.4ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 haohao, 32.2ms\n",
            "Speed: 8.3ms preprocess, 32.2ms inference, 3.7ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 haohao, 25.9ms\n",
            "Speed: 5.4ms preprocess, 25.9ms inference, 2.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 haohao, 25.9ms\n",
            "Speed: 4.9ms preprocess, 25.9ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 haohao, 25.9ms\n",
            "Speed: 4.9ms preprocess, 25.9ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 haohao, 25.9ms\n",
            "Speed: 5.4ms preprocess, 25.9ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 haohao, 25.9ms\n",
            "Speed: 8.4ms preprocess, 25.9ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 25.9ms\n",
            "Speed: 6.1ms preprocess, 25.9ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 haohao, 25.9ms\n",
            "Speed: 6.3ms preprocess, 25.9ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 haohao, 25.9ms\n",
            "Speed: 5.9ms preprocess, 25.9ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 29.8ms\n",
            "Speed: 6.0ms preprocess, 29.8ms inference, 4.7ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 haohao, 25.9ms\n",
            "Speed: 5.0ms preprocess, 25.9ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 haohao, 27.3ms\n",
            "Speed: 5.8ms preprocess, 27.3ms inference, 9.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 haohao, 30.8ms\n",
            "Speed: 5.8ms preprocess, 30.8ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 2 haohaos, 25.9ms\n",
            "Speed: 4.7ms preprocess, 25.9ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 haohao, 25.8ms\n",
            "Speed: 4.4ms preprocess, 25.8ms inference, 2.7ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 haohao, 29.9ms\n",
            "Speed: 9.7ms preprocess, 29.9ms inference, 2.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 25.9ms\n",
            "Speed: 6.4ms preprocess, 25.9ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 25.9ms\n",
            "Speed: 6.7ms preprocess, 25.9ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 haohao, 25.9ms\n",
            "Speed: 6.6ms preprocess, 25.9ms inference, 2.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 27.3ms\n",
            "Speed: 10.9ms preprocess, 27.3ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 34.6ms\n",
            "Speed: 10.0ms preprocess, 34.6ms inference, 5.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 haohao, 41.3ms\n",
            "Speed: 4.7ms preprocess, 41.3ms inference, 1.7ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 haohao, 27.7ms\n",
            "Speed: 8.5ms preprocess, 27.7ms inference, 6.6ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 haohao, 34.6ms\n",
            "Speed: 9.1ms preprocess, 34.6ms inference, 8.6ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 haohao, 48.2ms\n",
            "Speed: 5.2ms preprocess, 48.2ms inference, 7.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 haohao, 29.2ms\n",
            "Speed: 8.7ms preprocess, 29.2ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 haohao, 34.0ms\n",
            "Speed: 7.2ms preprocess, 34.0ms inference, 8.4ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 haohao, 28.8ms\n",
            "Speed: 7.2ms preprocess, 28.8ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 haohao, 34.5ms\n",
            "Speed: 6.6ms preprocess, 34.5ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 haohao, 39.8ms\n",
            "Speed: 8.1ms preprocess, 39.8ms inference, 1.7ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 haohao, 28.8ms\n",
            "Speed: 4.6ms preprocess, 28.8ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 1 haohao, 28.5ms\n",
            "Speed: 7.5ms preprocess, 28.5ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 haohao, 27.7ms\n",
            "Speed: 9.9ms preprocess, 27.7ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 haohao, 30.6ms\n",
            "Speed: 5.9ms preprocess, 30.6ms inference, 1.6ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 haohao, 28.9ms\n",
            "Speed: 5.5ms preprocess, 28.9ms inference, 3.5ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 haohao, 31.5ms\n",
            "Speed: 4.8ms preprocess, 31.5ms inference, 1.7ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 haohao, 27.3ms\n",
            "Speed: 4.9ms preprocess, 27.3ms inference, 9.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 haohao, 25.9ms\n",
            "Speed: 11.7ms preprocess, 25.9ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 34.1ms\n",
            "Speed: 12.4ms preprocess, 34.1ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 haohao, 25.8ms\n",
            "Speed: 11.1ms preprocess, 25.8ms inference, 8.5ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 haohao, 39.0ms\n",
            "Speed: 4.7ms preprocess, 39.0ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 haohao, 26.3ms\n",
            "Speed: 8.4ms preprocess, 26.3ms inference, 2.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 haohao, 29.4ms\n",
            "Speed: 8.0ms preprocess, 29.4ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 1 haohao, 25.9ms\n",
            "Speed: 5.8ms preprocess, 25.9ms inference, 2.5ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 1 haohao, 25.9ms\n",
            "Speed: 13.8ms preprocess, 25.9ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 1 haohao, 27.5ms\n",
            "Speed: 13.2ms preprocess, 27.5ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 haohao, 25.9ms\n",
            "Speed: 4.8ms preprocess, 25.9ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 haohao, 25.9ms\n",
            "Speed: 8.2ms preprocess, 25.9ms inference, 2.5ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 1 haohao, 25.9ms\n",
            "Speed: 6.0ms preprocess, 25.9ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 25.9ms\n",
            "Speed: 5.5ms preprocess, 25.9ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 25.9ms\n",
            "Speed: 4.7ms preprocess, 25.9ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongCas, 1 haohao, 25.9ms\n",
            "Speed: 5.0ms preprocess, 25.9ms inference, 2.4ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 haohao, 25.9ms\n",
            "Speed: 4.8ms preprocess, 25.9ms inference, 2.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 haohao, 26.2ms\n",
            "Speed: 6.4ms preprocess, 26.2ms inference, 7.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 haohao, 26.1ms\n",
            "Speed: 5.9ms preprocess, 26.1ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 26.0ms\n",
            "Speed: 5.4ms preprocess, 26.0ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 26.0ms\n",
            "Speed: 5.0ms preprocess, 26.0ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 25.9ms\n",
            "Speed: 5.6ms preprocess, 25.9ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 haohao, 26.1ms\n",
            "Speed: 5.6ms preprocess, 26.1ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 TuongOt, 1 haohao, 25.9ms\n",
            "Speed: 5.5ms preprocess, 25.9ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 haohao, 25.9ms\n",
            "Speed: 4.9ms preprocess, 25.9ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 TuongOt, 1 haohao, 25.8ms\n",
            "Speed: 5.1ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 TuongOt, 1 haohao, 27.9ms\n",
            "Speed: 5.4ms preprocess, 27.9ms inference, 3.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 TuongOt, 1 haohao, 28.3ms\n",
            "Speed: 5.2ms preprocess, 28.3ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 haohao, 27.5ms\n",
            "Speed: 5.4ms preprocess, 27.5ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 TuongOt, 1 haohao, 25.9ms\n",
            "Speed: 6.0ms preprocess, 25.9ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 TuongOt, 1 haohao, 25.9ms\n",
            "Speed: 6.9ms preprocess, 25.9ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 25.9ms\n",
            "Speed: 5.3ms preprocess, 25.9ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 TuongOt, 25.9ms\n",
            "Speed: 4.9ms preprocess, 25.9ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 TuongOt, 25.9ms\n",
            "Speed: 4.7ms preprocess, 25.9ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 31.9ms\n",
            "Speed: 7.5ms preprocess, 31.9ms inference, 3.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 26.0ms\n",
            "Speed: 5.2ms preprocess, 26.0ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 25.8ms\n",
            "Speed: 4.7ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 25.9ms\n",
            "Speed: 6.1ms preprocess, 25.9ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 TuongOt, 26.1ms\n",
            "Speed: 5.5ms preprocess, 26.1ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 25.9ms\n",
            "Speed: 8.3ms preprocess, 25.9ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 haohao, 25.9ms\n",
            "Speed: 6.6ms preprocess, 25.9ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 TuongOt, 25.8ms\n",
            "Speed: 6.2ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 25.9ms\n",
            "Speed: 10.8ms preprocess, 25.9ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 TuongOt, 25.9ms\n",
            "Speed: 7.6ms preprocess, 25.9ms inference, 2.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongOt, 25.9ms\n",
            "Speed: 5.2ms preprocess, 25.9ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongOt, 27.5ms\n",
            "Speed: 6.8ms preprocess, 27.5ms inference, 2.6ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongOt, 25.9ms\n",
            "Speed: 5.4ms preprocess, 25.9ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 1 TuongOt, 25.8ms\n",
            "Speed: 5.3ms preprocess, 25.8ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 25.9ms\n",
            "Speed: 5.0ms preprocess, 25.9ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 25.8ms\n",
            "Speed: 4.6ms preprocess, 25.8ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 25.8ms\n",
            "Speed: 4.6ms preprocess, 25.8ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 25.8ms\n",
            "Speed: 4.9ms preprocess, 25.8ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 26.1ms\n",
            "Speed: 4.9ms preprocess, 26.1ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 25.8ms\n",
            "Speed: 4.9ms preprocess, 25.8ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 25.9ms\n",
            "Speed: 4.3ms preprocess, 25.9ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 29.6ms\n",
            "Speed: 9.4ms preprocess, 29.6ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 25.9ms\n",
            "Speed: 6.2ms preprocess, 25.9ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 25.9ms\n",
            "Speed: 5.2ms preprocess, 25.9ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 25.9ms\n",
            "Speed: 5.8ms preprocess, 25.9ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 25.8ms\n",
            "Speed: 4.6ms preprocess, 25.8ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 25.9ms\n",
            "Speed: 6.0ms preprocess, 25.9ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 25.8ms\n",
            "Speed: 4.5ms preprocess, 25.8ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 25.9ms\n",
            "Speed: 4.8ms preprocess, 25.9ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongCa, 25.8ms\n",
            "Speed: 4.7ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 28.0ms\n",
            "Speed: 5.8ms preprocess, 28.0ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 25.8ms\n",
            "Speed: 5.3ms preprocess, 25.8ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 25.9ms\n",
            "Speed: 6.1ms preprocess, 25.9ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 25.9ms\n",
            "Speed: 5.2ms preprocess, 25.9ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 25.9ms\n",
            "Speed: 8.1ms preprocess, 25.9ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 25.8ms\n",
            "Speed: 6.3ms preprocess, 25.8ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 25.9ms\n",
            "Speed: 13.7ms preprocess, 25.9ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 25.9ms\n",
            "Speed: 6.4ms preprocess, 25.9ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 26.6ms\n",
            "Speed: 7.5ms preprocess, 26.6ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 27.5ms\n",
            "Speed: 7.2ms preprocess, 27.5ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongOt, 25.9ms\n",
            "Speed: 5.1ms preprocess, 25.9ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 25.9ms\n",
            "Speed: 6.8ms preprocess, 25.9ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 25.9ms\n",
            "Speed: 11.8ms preprocess, 25.9ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 haohao, 25.9ms\n",
            "Speed: 5.1ms preprocess, 25.9ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 25.8ms\n",
            "Speed: 5.8ms preprocess, 25.8ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 28.6ms\n",
            "Speed: 4.3ms preprocess, 28.6ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 36.1ms\n",
            "Speed: 7.1ms preprocess, 36.1ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 37.7ms\n",
            "Speed: 8.9ms preprocess, 37.7ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 25.9ms\n",
            "Speed: 7.6ms preprocess, 25.9ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 31.5ms\n",
            "Speed: 13.2ms preprocess, 31.5ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 25.8ms\n",
            "Speed: 4.9ms preprocess, 25.8ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 26.6ms\n",
            "Speed: 8.5ms preprocess, 26.6ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 25.8ms\n",
            "Speed: 9.4ms preprocess, 25.8ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 33.5ms\n",
            "Speed: 6.6ms preprocess, 33.5ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 haohao, 29.1ms\n",
            "Speed: 5.2ms preprocess, 29.1ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 33.0ms\n",
            "Speed: 10.5ms preprocess, 33.0ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 25.8ms\n",
            "Speed: 19.7ms preprocess, 25.8ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 26.0ms\n",
            "Speed: 11.8ms preprocess, 26.0ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 haohao, 28.5ms\n",
            "Speed: 10.2ms preprocess, 28.5ms inference, 1.7ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 38.2ms\n",
            "Speed: 9.1ms preprocess, 38.2ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 39.1ms\n",
            "Speed: 5.7ms preprocess, 39.1ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 haohao, 32.8ms\n",
            "Speed: 4.5ms preprocess, 32.8ms inference, 1.6ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 haohao, 29.9ms\n",
            "Speed: 5.4ms preprocess, 29.9ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 haohao, 30.5ms\n",
            "Speed: 8.8ms preprocess, 30.5ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 haohao, 27.4ms\n",
            "Speed: 7.2ms preprocess, 27.4ms inference, 2.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 haohao, 34.4ms\n",
            "Speed: 6.5ms preprocess, 34.4ms inference, 10.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 haohao, 26.3ms\n",
            "Speed: 8.3ms preprocess, 26.3ms inference, 8.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 haohao, 27.0ms\n",
            "Speed: 8.3ms preprocess, 27.0ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 haohao, 32.7ms\n",
            "Speed: 7.6ms preprocess, 32.7ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 haohao, 32.4ms\n",
            "Speed: 4.9ms preprocess, 32.4ms inference, 3.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 haohao, 33.1ms\n",
            "Speed: 17.0ms preprocess, 33.1ms inference, 9.4ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongOt, 1 haohao, 31.2ms\n",
            "Speed: 12.4ms preprocess, 31.2ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongOt, 1 haohao, 25.9ms\n",
            "Speed: 5.9ms preprocess, 25.9ms inference, 2.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongOt, 1 haohao, 25.9ms\n",
            "Speed: 6.1ms preprocess, 25.9ms inference, 2.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongOt, 1 haohao, 25.9ms\n",
            "Speed: 5.8ms preprocess, 25.9ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongOt, 1 haohao, 25.9ms\n",
            "Speed: 5.9ms preprocess, 25.9ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongOt, 1 haohao, 26.4ms\n",
            "Speed: 6.1ms preprocess, 26.4ms inference, 3.7ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongOt, 1 haohao, 25.8ms\n",
            "Speed: 4.2ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 haohaos, 28.2ms\n",
            "Speed: 6.4ms preprocess, 28.2ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 haohaos, 25.9ms\n",
            "Speed: 4.6ms preprocess, 25.9ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 25.9ms\n",
            "Speed: 5.9ms preprocess, 25.9ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 25.9ms\n",
            "Speed: 5.4ms preprocess, 25.9ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongOts, 25.9ms\n",
            "Speed: 5.0ms preprocess, 25.9ms inference, 4.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 27.1ms\n",
            "Speed: 6.9ms preprocess, 27.1ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 25.9ms\n",
            "Speed: 4.6ms preprocess, 25.9ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 25.9ms\n",
            "Speed: 4.8ms preprocess, 25.9ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 25.8ms\n",
            "Speed: 6.6ms preprocess, 25.8ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 25.9ms\n",
            "Speed: 6.1ms preprocess, 25.9ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 25.9ms\n",
            "Speed: 5.1ms preprocess, 25.9ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 25.9ms\n",
            "Speed: 6.6ms preprocess, 25.9ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 25.9ms\n",
            "Speed: 4.9ms preprocess, 25.9ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 27.3ms\n",
            "Speed: 9.0ms preprocess, 27.3ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 25.9ms\n",
            "Speed: 5.8ms preprocess, 25.9ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongOt, 25.9ms\n",
            "Speed: 4.6ms preprocess, 25.9ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongOts, 25.9ms\n",
            "Speed: 7.8ms preprocess, 25.9ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 25.9ms\n",
            "Speed: 5.4ms preprocess, 25.9ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 25.9ms\n",
            "Speed: 5.8ms preprocess, 25.9ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 25.9ms\n",
            "Speed: 5.9ms preprocess, 25.9ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongOts, 26.1ms\n",
            "Speed: 5.1ms preprocess, 26.1ms inference, 5.7ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongOt, 25.9ms\n",
            "Speed: 5.3ms preprocess, 25.9ms inference, 3.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongOt, 25.9ms\n",
            "Speed: 5.4ms preprocess, 25.9ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongOt, 25.9ms\n",
            "Speed: 6.0ms preprocess, 25.9ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongOts, 25.9ms\n",
            "Speed: 4.8ms preprocess, 25.9ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongOts, 25.9ms\n",
            "Speed: 5.0ms preprocess, 25.9ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongOt, 25.9ms\n",
            "Speed: 4.4ms preprocess, 25.9ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 26.0ms\n",
            "Speed: 5.8ms preprocess, 26.0ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 25.9ms\n",
            "Speed: 5.7ms preprocess, 25.9ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongOt, 25.8ms\n",
            "Speed: 4.7ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 25.9ms\n",
            "Speed: 5.3ms preprocess, 25.9ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 25.9ms\n",
            "Speed: 5.3ms preprocess, 25.9ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 26.4ms\n",
            "Speed: 4.6ms preprocess, 26.4ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongOts, 25.9ms\n",
            "Speed: 5.3ms preprocess, 25.9ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongOt, 25.9ms\n",
            "Speed: 10.9ms preprocess, 25.9ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongOt, 25.9ms\n",
            "Speed: 4.7ms preprocess, 25.9ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 25.8ms\n",
            "Speed: 6.2ms preprocess, 25.8ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 26.7ms\n",
            "Speed: 5.1ms preprocess, 26.7ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 26.0ms\n",
            "Speed: 8.2ms preprocess, 26.0ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 25.9ms\n",
            "Speed: 4.9ms preprocess, 25.9ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 25.9ms\n",
            "Speed: 5.5ms preprocess, 25.9ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 25.9ms\n",
            "Speed: 6.1ms preprocess, 25.9ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 25.9ms\n",
            "Speed: 5.4ms preprocess, 25.9ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 25.8ms\n",
            "Speed: 4.1ms preprocess, 25.8ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 25.8ms\n",
            "Speed: 4.5ms preprocess, 25.8ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 26.0ms\n",
            "Speed: 5.7ms preprocess, 26.0ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 25.9ms\n",
            "Speed: 4.9ms preprocess, 25.9ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongOt, 25.9ms\n",
            "Speed: 5.2ms preprocess, 25.9ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongOt, 25.9ms\n",
            "Speed: 5.0ms preprocess, 25.9ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 25.9ms\n",
            "Speed: 5.1ms preprocess, 25.9ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongOt, 25.9ms\n",
            "Speed: 6.6ms preprocess, 25.9ms inference, 3.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongOts, 25.9ms\n",
            "Speed: 5.0ms preprocess, 25.9ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongOt, 25.9ms\n",
            "Speed: 5.0ms preprocess, 25.9ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongOts, 25.8ms\n",
            "Speed: 5.4ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongOts, 25.9ms\n",
            "Speed: 4.7ms preprocess, 25.9ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongOts, 25.8ms\n",
            "Speed: 4.4ms preprocess, 25.8ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongOts, 25.9ms\n",
            "Speed: 5.3ms preprocess, 25.9ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 3 TuongOts, 25.9ms\n",
            "Speed: 4.8ms preprocess, 25.9ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongOts, 29.7ms\n",
            "Speed: 6.3ms preprocess, 29.7ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongOts, 26.1ms\n",
            "Speed: 9.7ms preprocess, 26.1ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongOt, 25.9ms\n",
            "Speed: 5.3ms preprocess, 25.9ms inference, 5.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongOts, 25.9ms\n",
            "Speed: 4.8ms preprocess, 25.9ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 2 TuongOts, 25.9ms\n",
            "Speed: 4.8ms preprocess, 25.9ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongOt, 25.8ms\n",
            "Speed: 4.2ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongOt, 25.9ms\n",
            "Speed: 4.3ms preprocess, 25.9ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongOt, 25.9ms\n",
            "Speed: 5.2ms preprocess, 25.9ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongOt, 25.9ms\n",
            "Speed: 5.2ms preprocess, 25.9ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongOt, 25.9ms\n",
            "Speed: 4.8ms preprocess, 25.9ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 25.8ms\n",
            "Speed: 4.6ms preprocess, 25.8ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongOt, 26.0ms\n",
            "Speed: 4.8ms preprocess, 26.0ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 1 TuongOt, 25.8ms\n",
            "Speed: 4.9ms preprocess, 25.8ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 27.5ms\n",
            "Speed: 5.0ms preprocess, 27.5ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 36.1ms\n",
            "Speed: 9.9ms preprocess, 36.1ms inference, 8.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 35.1ms\n",
            "Speed: 4.5ms preprocess, 35.1ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 28.8ms\n",
            "Speed: 10.5ms preprocess, 28.8ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 25.8ms\n",
            "Speed: 5.4ms preprocess, 25.8ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 25.9ms\n",
            "Speed: 4.7ms preprocess, 25.9ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 33.1ms\n",
            "Speed: 6.2ms preprocess, 33.1ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 25.9ms\n",
            "Speed: 4.6ms preprocess, 25.9ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 28.9ms\n",
            "Speed: 7.1ms preprocess, 28.9ms inference, 7.3ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 25.8ms\n",
            "Speed: 4.6ms preprocess, 25.8ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 31.1ms\n",
            "Speed: 4.8ms preprocess, 31.1ms inference, 5.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 27.0ms\n",
            "Speed: 5.0ms preprocess, 27.0ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 27.6ms\n",
            "Speed: 11.4ms preprocess, 27.6ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 27.8ms\n",
            "Speed: 4.6ms preprocess, 27.8ms inference, 0.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 25.9ms\n",
            "Speed: 4.3ms preprocess, 25.9ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 36.8ms\n",
            "Speed: 5.2ms preprocess, 36.8ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 40.7ms\n",
            "Speed: 10.8ms preprocess, 40.7ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 25.9ms\n",
            "Speed: 8.8ms preprocess, 25.9ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 26.2ms\n",
            "Speed: 5.8ms preprocess, 26.2ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 33.4ms\n",
            "Speed: 12.0ms preprocess, 33.4ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 25.9ms\n",
            "Speed: 4.7ms preprocess, 25.9ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 27.9ms\n",
            "Speed: 4.5ms preprocess, 27.9ms inference, 0.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 25.9ms\n",
            "Speed: 4.6ms preprocess, 25.9ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 42.9ms\n",
            "Speed: 7.0ms preprocess, 42.9ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 25.9ms\n",
            "Speed: 4.8ms preprocess, 25.9ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 28.0ms\n",
            "Speed: 5.2ms preprocess, 28.0ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 25.9ms\n",
            "Speed: 5.0ms preprocess, 25.9ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 31.9ms\n",
            "Speed: 5.0ms preprocess, 31.9ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 29.4ms\n",
            "Speed: 4.9ms preprocess, 29.4ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 30.0ms\n",
            "Speed: 5.2ms preprocess, 30.0ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 25.9ms\n",
            "Speed: 9.0ms preprocess, 25.9ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 25.9ms\n",
            "Speed: 5.8ms preprocess, 25.9ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 26.3ms\n",
            "Speed: 5.0ms preprocess, 26.3ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 25.9ms\n",
            "Speed: 6.9ms preprocess, 25.9ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 25.9ms\n",
            "Speed: 5.2ms preprocess, 25.9ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 31.6ms\n",
            "Speed: 8.9ms preprocess, 31.6ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 25.9ms\n",
            "Speed: 4.9ms preprocess, 25.9ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 27.6ms\n",
            "Speed: 5.0ms preprocess, 27.6ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 25.9ms\n",
            "Speed: 5.7ms preprocess, 25.9ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 25.9ms\n",
            "Speed: 4.9ms preprocess, 25.9ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 25.8ms\n",
            "Speed: 7.0ms preprocess, 25.8ms inference, 0.7ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 25.9ms\n",
            "Speed: 4.6ms preprocess, 25.9ms inference, 0.7ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 512x640 (no detections), 25.9ms\n",
            "Speed: 4.7ms preprocess, 25.9ms inference, 0.7ms postprocess per image at shape (1, 3, 512, 640)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Video object>"
            ],
            "text/html": [
              "<video src=\"/content/drive/MyDrive/output_video.mp4\" controls  >\n",
              "      Your browser does not support the <code>video</code> element.\n",
              "    </video>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
        "from ultralytics import YOLO\n",
        "from google.colab.patches import cv2_imshow  # Äá»ƒ hiá»ƒn thá»‹ khung hÃ¬nh náº¿u cáº§n\n",
        "\n",
        "# Config giÃ¡ trá»‹\n",
        "video_path = \"/content/drive/MyDrive/testVideo/IMG_0757.mp4\"  # ÄÆ°á»ng dáº«n video Ä‘áº§u vÃ o\n",
        "output_video_path = \"/content/drive/MyDrive/output_video.mp4\"  # ÄÆ°á»ng dáº«n Ä‘áº¿n tá»‡p video Ä‘áº§u ra\n",
        "conf_threshold = 0.5  # NgÆ°á»¡ng confidence Ä‘á»ƒ cháº¥p nháº­n cÃ¡c váº­t thá»ƒ detect\n",
        "tracking_class = None  # None: theo dÃµi táº¥t cáº£ cÃ¡c class\n",
        "\n",
        "# Khá»Ÿi táº¡o DeepSort\n",
        "tracker = DeepSort(max_age=30)\n",
        "\n",
        "# Khá»Ÿi táº¡o YOLOv8\n",
        "device = \"mps:0\"  # \"cuda\": GPU, \"cpu\": CPU, \"mps:0\" cho Mac\n",
        "model = YOLO(\"/content/drive/MyDrive/runs/detect/train10/weights/best.pt\")  # Khá»Ÿi táº¡o mÃ´ hÃ¬nh YOLOv8\n",
        "\n",
        "# Load classname tá»« file classes.names\n",
        "with open(\"/content/drive/MyDrive/data_exp/classes.names\") as f:\n",
        "    class_names = f.read().strip().split('\\n')\n",
        "\n",
        "# Táº¡o mÃ u ngáº«u nhiÃªn cho cÃ¡c class\n",
        "colors = np.random.randint(0, 255, size=(len(class_names), 3))\n",
        "\n",
        "# Khá»Ÿi táº¡o biáº¿n Ä‘áº¿m vÃ  checkpoint\n",
        "count = 0  # Tá»•ng sá»‘ Ä‘á»‘i tÆ°á»£ng vÆ°á»£t qua checkpoint\n",
        "class_counts = {name: 0 for name in class_names}  # Dictionary Ä‘á»ƒ Ä‘áº¿m tá»«ng class\n",
        "crossed_objects = {}  # Dictionary Ä‘á»ƒ lÆ°u tráº¡ng thÃ¡i cÃ¡c váº­t thá»ƒ Ä‘Ã£ qua váº¡ch checkpoint hay chÆ°a\n",
        "\n",
        "# Khá»Ÿi táº¡o VideoCapture Ä‘á»ƒ Ä‘á»c tá»« file video\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "# Láº¥y thÃ´ng tin video Ä‘á»ƒ táº¡o video Ä‘áº§u ra\n",
        "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "# Khá»Ÿi táº¡o VideoWriter Ä‘á»ƒ ghi video\n",
        "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
        "out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
        "\n",
        "# Äá»‹nh nghÄ©a váº¡ch checkpoint (á»Ÿ giá»¯a khung hÃ¬nh)\n",
        "checkpoint_y = int(frame_height // 2)\n",
        "\n",
        "\n",
        "# HÃ m Ä‘á»ƒ cáº­p nháº­t vÃ  váº½ cÃ¡c track lÃªn khung hÃ¬nh\n",
        "def update_and_draw_tracks(tracks, frame):\n",
        "    for track in tracks:\n",
        "        if track.is_confirmed():\n",
        "            track_id = track.track_id  # Láº¥y ID cá»§a váº­t thá»ƒ\n",
        "\n",
        "            # Láº¥y tá»a Ä‘á»™, class_id Ä‘á»ƒ váº½ lÃªn hÃ¬nh áº£nh\n",
        "            ltrb = track.to_ltrb()  # Chuyá»ƒn Ä‘á»•i track thÃ nh [x1, y1, x2, y2]\n",
        "            class_id = track.get_det_class()\n",
        "\n",
        "            # Kiá»ƒm tra náº¿u class_id náº±m ngoÃ i giá»›i háº¡n cá»§a class_names\n",
        "            if class_id >= len(class_names) or class_id < 0:\n",
        "                continue  # Bá» qua track nÃ y náº¿u class_id khÃ´ng há»£p lá»‡\n",
        "\n",
        "            x1, y1, x2, y2 = map(int, ltrb)\n",
        "\n",
        "            # Äáº£m báº£o ráº±ng class_id khÃ´ng vÆ°á»£t quÃ¡ sá»‘ mÃ u trong máº£ng colors\n",
        "            color = colors[class_id % len(colors)]  # Sá»­ dá»¥ng modulo Ä‘á»ƒ trÃ¡nh lá»—i\n",
        "            B, G, R = map(int, color)\n",
        "\n",
        "            label = \"{}-{}\".format(class_names[class_id], track_id)  # Táº¡o nhÃ£n cho váº­t thá»ƒ\n",
        "\n",
        "            # Váº½ bounding box vÃ  nhÃ£n lÃªn hÃ¬nh\n",
        "            cv2.rectangle(frame, (x1, y1), (x2, y2), (B, G, R), 2)\n",
        "            cv2.rectangle(frame, (x1 - 1, y1 - 20), (x1 + len(label) * 12, y1), (B, G, R), -1)\n",
        "            cv2.putText(frame, label, (x1 + 5, y1 - 8), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
        "\n",
        "    return frame\n",
        "\n",
        "# Load prices from file class.price\n",
        "with open(\"/content/drive/MyDrive/data_exp/classes.price\") as f:\n",
        "    class_prices = list(map(float, f.read().strip().split('\\n')))  # Chuyá»ƒn Ä‘á»•i tá»«ng giÃ¡ trá»‹ trong file thÃ nh float\n",
        "\n",
        "# Khá»Ÿi táº¡o biáº¿n Ä‘á»ƒ lÆ°u tá»•ng giÃ¡ trá»‹\n",
        "total_value = 0\n",
        "\n",
        "# HÃ m Ä‘á»ƒ Ä‘áº¿m sá»‘ lÆ°á»£ng Ä‘á»‘i tÆ°á»£ng Ä‘Ã£ vÆ°á»£t qua checkpoint vÃ  tÃ­nh tá»•ng giÃ¡ trá»‹\n",
        "def count_objects_passing_checkpoint(tracks, frame, checkpoint_y):\n",
        "    global count, crossed_objects, total_value\n",
        "    for track in tracks:\n",
        "        if track.is_confirmed():\n",
        "            track_id = track.track_id\n",
        "            class_id = track.get_det_class()\n",
        "\n",
        "            # Kiá»ƒm tra náº¿u class_id náº±m ngoÃ i giá»›i háº¡n cá»§a class_names\n",
        "            if class_id >= len(class_names) or class_id < 0:\n",
        "                continue  # Bá» qua track nÃ y náº¿u class_id khÃ´ng há»£p lá»‡\n",
        "\n",
        "            # Láº¥y tá»a Ä‘á»™ tÃ¢m cá»§a bounding box\n",
        "            ltrb = track.to_ltrb()\n",
        "            x1, y1, x2, y2 = map(int, ltrb)\n",
        "            object_center_y = (y1 + y2) // 2\n",
        "\n",
        "            # Kiá»ƒm tra xem váº­t thá»ƒ cÃ³ Ä‘i qua váº¡ch checkpoint chÆ°a\n",
        "            if track_id not in crossed_objects:\n",
        "                crossed_objects[track_id] = {'crossed': False, 'last_position_y': object_center_y}  # ÄÃ¡nh dáº¥u váº­t thá»ƒ chÆ°a qua váº¡ch\n",
        "\n",
        "            # Náº¿u váº­t thá»ƒ chÆ°a qua váº¡ch vÃ  tÃ¢m cá»§a bounding box vÆ°á»£t qua váº¡ch checkpoint\n",
        "            if not crossed_objects[track_id]['crossed']:\n",
        "                # Äiá»u kiá»‡n chá»‰ cá»™ng khi váº­t thá»ƒ Ä‘i tá»« phÃ­a trÃªn váº¡ch xuá»‘ng dÆ°á»›i\n",
        "                if crossed_objects[track_id]['last_position_y'] < checkpoint_y and object_center_y > checkpoint_y:\n",
        "                    count += 1  # TÄƒng bá»™ Ä‘áº¿m tá»•ng\n",
        "                    crossed_objects[track_id]['crossed'] = True  # ÄÃ¡nh dáº¥u lÃ  váº­t thá»ƒ nÃ y Ä‘Ã£ qua váº¡ch\n",
        "                    class_counts[class_names[class_id]] += 1  # TÄƒng bá»™ Ä‘áº¿m cho class tÆ°Æ¡ng á»©ng\n",
        "\n",
        "                    # Cá»™ng giÃ¡ trá»‹ cá»§a váº­t thá»ƒ vÃ o tá»•ng giÃ¡ trá»‹\n",
        "                    total_value += class_prices[class_id]\n",
        "\n",
        "            # Cáº­p nháº­t vá»‹ trÃ­ y cuá»‘i cÃ¹ng cá»§a váº­t thá»ƒ\n",
        "            crossed_objects[track_id]['last_position_y'] = object_center_y\n",
        "\n",
        "    # Hiá»ƒn thá»‹ tá»•ng sá»‘ lÆ°á»£ng Ä‘á»‘i tÆ°á»£ng Ä‘Ã£ vÆ°á»£t qua checkpoint\n",
        "    cv2.putText(frame, f'COUNT: {count}', (frame_width // 2 - 50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
        "\n",
        "    # Hiá»ƒn thá»‹ tá»•ng giÃ¡ trá»‹ cá»§a cÃ¡c Ä‘á»‘i tÆ°á»£ng Ä‘Ã£ qua checkpoint\n",
        "    cv2.putText(frame, f'Total Value: {total_value}', (frame_width // 2 - 50, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
        "\n",
        "    # Hiá»ƒn thá»‹ sá»‘ lÆ°á»£ng cá»§a tá»«ng class Ä‘Ã£ qua checkpoint\n",
        "    y_offset = 130\n",
        "    for class_name, class_count in class_counts.items():\n",
        "        cv2.putText(frame, f'{class_name}: {class_count}', (frame_width // 2 - 50, y_offset), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
        "        y_offset += 30  # TÄƒng vá»‹ trÃ­ y cho má»—i class name\n",
        "\n",
        "    return frame\n",
        "\n",
        "\n",
        "while True:\n",
        "    # Äá»c tá»«ng frame tá»« video\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break  # Dá»«ng náº¿u khÃ´ng cÃ²n frame nÃ o Ä‘á»ƒ Ä‘á»c\n",
        "\n",
        "    # ÄÆ°a khung hÃ¬nh qua model YOLOv8 Ä‘á»ƒ detect cÃ¡c váº­t thá»ƒ\n",
        "    results = model(frame)\n",
        "\n",
        "    # LÆ°u káº¿t quáº£ detect vÃ o danh sÃ¡ch\n",
        "    detect = []\n",
        "    for detect_object in results[0].boxes.data.tolist():  # Sá»­ dá»¥ng káº¿t quáº£ tá»« YOLOv8\n",
        "        detect_object = list(detect_object)  # Chuyá»ƒn Ä‘á»•i thÃ nh danh sÃ¡ch\n",
        "        x1, y1, x2, y2, confidence, class_id = list(map(int, detect_object[:4])) + [detect_object[4], int(detect_object[5])]\n",
        "\n",
        "        if tracking_class is None:\n",
        "            if confidence < conf_threshold:\n",
        "                continue\n",
        "        else:\n",
        "            if class_id != tracking_class or confidence < conf_threshold:\n",
        "                continue\n",
        "\n",
        "        # LÆ°u káº¿t quáº£ phÃ¡t hiá»‡n thÃ nh [bounding box, confidence, class_id]\n",
        "        detect.append([[x1, y1, x2 - x1, y2 - y1], confidence, class_id])\n",
        "\n",
        "    # Cáº­p nháº­t cÃ¡c track vÃ  gÃ¡n ID cho cÃ¡c váº­t thá»ƒ báº±ng DeepSort\n",
        "    tracks = tracker.update_tracks(detect, frame=frame)\n",
        "\n",
        "    # Váº½ váº¡ch checkpoint\n",
        "    cv2.line(frame, (0, checkpoint_y), (frame_width, checkpoint_y), (255, 0, 0), 2)  # Váº¡ch mÃ u xanh dÆ°Æ¡ng\n",
        "\n",
        "    # Cáº­p nháº­t vÃ  váº½ cÃ¡c track lÃªn frame\n",
        "    frame = update_and_draw_tracks(tracks, frame)\n",
        "\n",
        "    # Äáº¿m sá»‘ lÆ°á»£ng Ä‘á»‘i tÆ°á»£ng Ä‘Ã£ qua checkpoint\n",
        "    frame = count_objects_passing_checkpoint(tracks, frame, checkpoint_y)\n",
        "\n",
        "    # Ghi khung hÃ¬nh vÃ o video Ä‘áº§u ra\n",
        "    out.write(frame)\n",
        "\n",
        "# Giáº£i phÃ³ng cÃ¡c tÃ i nguyÃªn\n",
        "cap.release()\n",
        "out.release()\n",
        "\n",
        "# Äá»ƒ hiá»ƒn thá»‹ video Ä‘Ã£ ghi, báº¡n cÃ³ thá»ƒ sá»­ dá»¥ng Ä‘oáº¡n mÃ£ dÆ°á»›i Ä‘Ã¢y\n",
        "from IPython.display import Video\n",
        "Video(output_video_path)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "x2u6Lf5PJJD6",
        "Pgc-jjZYNrPI",
        "pyDlR59ZJYzF"
      ],
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}